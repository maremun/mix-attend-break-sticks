{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revised and fixed code from https://github.com/JayParks/transformer (MT) for LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stripped the code from the JayParks repo for MT Transformer. Introduced a few updates and changes for speed, but it's still frustratingly slow. Possible improvement - speed it up.\n",
    "\n",
    "Another issue - hyperparameter search for language modelling (number of heads, number of self-attention layers, etc). Does not work well from the box. This might be of help https://arxiv.org/pdf/1804.00247.pdf.\n",
    "\n",
    "Also consider parallelizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* Clean up\n",
    "* Add MoS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random sequence length batching\n",
    "\n",
    "This version of Transformer LM usesrandom sequence length batching.\n",
    "\n",
    "**NB** Make sure the src code does not assuem the existence of PAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from showprogress import showprogress\n",
    "\n",
    "import torch\n",
    "torch.cuda.device(0)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as pad\n",
    "from torch.nn.utils import clip_grad_norm_ as clip\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import const\n",
    "from data import *\n",
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(s, print_=True, log_=True):\n",
    "    if print_:\n",
    "        print(s)\n",
    "#     if log_:\n",
    "#         with open(os.path.join(args.save, 'log.txt'), 'a+') as f_log:\n",
    "#             f_log.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptb_datapath_train = 'data/penn/train.txt'\n",
    "# ptb_datapath_valid = 'data/penn/valid.txt'\n",
    "# ptb_datapath_test = 'data/penn/test.txt'\n",
    "\n",
    "# batch_size = 128\n",
    "\n",
    "# ptb_train = DataSet(ptb_datapath_train, batch_size, display_freq=0, max_len=90, trunc_len=90)\n",
    "# ptb_valid = DataSet(ptb_datapath_valid, batch_size, display_freq=0, max_len=90, trunc_len=90)\n",
    "# ptb_test = DataSet(ptb_datapath_test, batch_size, display_freq=0, max_len=90, trunc_len=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptb_train.build_dict()\n",
    "# ptb_valid.change_dict(ptb_train.dictionary)\n",
    "# ptb_test.change_dict(ptb_train.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7262, 128])\n",
      "torch.Size([7376, 10])\n",
      "torch.Size([82430, 1])\n"
     ]
    }
   ],
   "source": [
    "############ Optional: get data by tokens ###############\n",
    "corpus = Corpus('data/penn')\n",
    "eval_batch_size = 10\n",
    "test_batch_size = 1\n",
    "batch_size = 128\n",
    "train_data = batchify(corpus.train, batch_size, )\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, test_batch_size)\n",
    "\n",
    "#### how to take a batch ####\n",
    "# the data is already splitten into batch_size(now we need to decide about seq length)\n",
    "# batch_num = 2\n",
    "# batch = get_batch(train_data, batch_num, seq_len=35)\n",
    "\n",
    "\n",
    "#### TODO (if needed) ###\n",
    "# 1) repackage hiddens for learning by tokens\n",
    "# 2) learn not every step (depends on 1st point)\n",
    "# 3) add grad clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = len(corpus.dictionary) #corpus.dictionary.total # ptb_train.num_vocb\n",
    "n_tokens = voc_size\n",
    "emb_dim = 512\n",
    "d_k = 64\n",
    "d_v = 64\n",
    "n_layers = 2\n",
    "n_heads = 4\n",
    "d_ff = 1024\n",
    "max_tgt_seq_len = 90\n",
    "dropout = 0.0\n",
    "weighted_model = False\n",
    "share_proj_weight = True\n",
    "lr = 1e-6\n",
    "n_epochs = 1000\n",
    "clip_grad = 5\n",
    "warmup_steps = 2000\n",
    "log_interval=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharing target embedding and projection..\n"
     ]
    }
   ],
   "source": [
    "model = LMTransformer(n_layers, d_k, d_v, emb_dim, d_ff,\n",
    "                      n_heads, max_tgt_seq_len, voc_size,\n",
    "                      dropout, weighted_model, share_proj_weight)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=const.PAD)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "#opt = optim.Adam(model.trainable_params(), lr=lr)\n",
    "# lr_lambda = lambda epoch: 0.99 ** epoch\n",
    "#lrsched = StepLR(opt, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt0 = 70\n",
    "max_seq_len_delta = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "# seq_len is strange parameter\n",
    "def evaluate(data_source, model, ntokens, seq_len):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    batch = 0\n",
    "    for i in range(0, data_source.size(0) - 1, seq_len):\n",
    "        data, targets = get_batch(data_source, i, seq_len=seq_len)\n",
    "        seq_len = data.shape[1]\n",
    "        lengths = torch.ones(data.shape[0], device=device, dtype=torch.long) * seq_len\n",
    "\n",
    "        log_prob, self_attn = model(data, lengths)\n",
    "        loss = criterion(log_prob, targets.view(-1))\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batch += 1\n",
    "    return total_loss / batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# opt = optim.Adam(model.trainable_params(),betas=(0.9, 0.98), eps=1e-09, lr=lr)\n",
    "# i=0\n",
    "# best_val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 1, learning rate 0.000053 \n",
      "| epoch   0 | 30/103 batches | lr 0.0000 | ms/batch 68.70 | loss  4.54 | ppl    93.94\n",
      "| epoch   0 | 60/103 batches | lr 0.0000 | ms/batch 65.69 | loss  4.22 | ppl    68.11\n",
      "| epoch   0 | 90/103 batches | lr 0.0000 | ms/batch 64.56 | loss  4.03 | ppl    56.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   0 | time:  8.02s | valid loss  4.96 | valid ppl   141.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 2, learning rate 0.000054 \n",
      "| epoch   1 | 30/103 batches | lr 0.0000 | ms/batch 66.82 | loss  4.54 | ppl    94.05\n",
      "| epoch   1 | 60/103 batches | lr 0.0000 | ms/batch 65.97 | loss  4.20 | ppl    66.93\n",
      "| epoch   1 | 90/103 batches | lr 0.0000 | ms/batch 66.87 | loss  4.01 | ppl    55.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  7.99s | valid loss  4.95 | valid ppl   141.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 3, learning rate 0.000053 \n",
      "| epoch   2 | 30/103 batches | lr 0.0000 | ms/batch 68.45 | loss  4.55 | ppl    94.79\n",
      "| epoch   2 | 60/103 batches | lr 0.0000 | ms/batch 66.67 | loss  4.28 | ppl    71.90\n",
      "| epoch   2 | 90/103 batches | lr 0.0000 | ms/batch 69.15 | loss  4.05 | ppl    57.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  7.98s | valid loss  4.95 | valid ppl   141.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 4, learning rate 0.000053 \n",
      "| epoch   3 | 30/103 batches | lr 0.0000 | ms/batch 66.64 | loss  4.52 | ppl    92.01\n",
      "| epoch   3 | 60/103 batches | lr 0.0000 | ms/batch 67.96 | loss  4.32 | ppl    74.96\n",
      "| epoch   3 | 90/103 batches | lr 0.0000 | ms/batch 68.80 | loss  4.05 | ppl    57.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  7.96s | valid loss  4.95 | valid ppl   141.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 5, learning rate 0.000053 \n",
      "| epoch   4 | 30/103 batches | lr 0.0000 | ms/batch 68.31 | loss  4.56 | ppl    95.33\n",
      "| epoch   4 | 60/103 batches | lr 0.0000 | ms/batch 66.38 | loss  4.23 | ppl    68.61\n",
      "| epoch   4 | 90/103 batches | lr 0.0000 | ms/batch 65.71 | loss  3.92 | ppl    50.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  8.00s | valid loss  4.95 | valid ppl   141.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 6, learning rate 0.000054 \n",
      "| epoch   5 | 30/103 batches | lr 0.0000 | ms/batch 66.80 | loss  4.51 | ppl    91.04\n",
      "| epoch   5 | 60/103 batches | lr 0.0000 | ms/batch 65.99 | loss  4.16 | ppl    64.11\n",
      "| epoch   5 | 90/103 batches | lr 0.0000 | ms/batch 66.52 | loss  3.98 | ppl    53.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  8.01s | valid loss  4.95 | valid ppl   140.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 7, learning rate 0.000054 \n",
      "| epoch   6 | 30/103 batches | lr 0.0000 | ms/batch 66.92 | loss  4.52 | ppl    91.62\n",
      "| epoch   6 | 60/103 batches | lr 0.0000 | ms/batch 66.87 | loss  4.12 | ppl    61.86\n",
      "| epoch   6 | 90/103 batches | lr 0.0000 | ms/batch 67.61 | loss  3.93 | ppl    51.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  7.99s | valid loss  4.94 | valid ppl   140.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 8, learning rate 0.000053 \n",
      "| epoch   7 | 30/103 batches | lr 0.0000 | ms/batch 68.74 | loss  4.50 | ppl    90.42\n",
      "| epoch   7 | 60/103 batches | lr 0.0000 | ms/batch 69.57 | loss  4.26 | ppl    70.67\n",
      "| epoch   7 | 90/103 batches | lr 0.0000 | ms/batch 68.93 | loss  4.02 | ppl    55.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  7.94s | valid loss  4.95 | valid ppl   140.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 9, learning rate 0.000051 \n",
      "| epoch   8 | 30/103 batches | lr 0.0000 | ms/batch 68.37 | loss  4.50 | ppl    89.85\n",
      "| epoch   8 | 60/103 batches | lr 0.0000 | ms/batch 65.24 | loss  4.14 | ppl    62.66\n",
      "| epoch   8 | 90/103 batches | lr 0.0000 | ms/batch 68.35 | loss  4.04 | ppl    56.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  7.94s | valid loss  4.94 | valid ppl   140.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 10, learning rate 0.000053 \n",
      "| epoch   9 | 30/103 batches | lr 0.0000 | ms/batch 66.66 | loss  4.51 | ppl    90.70\n",
      "| epoch   9 | 60/103 batches | lr 0.0000 | ms/batch 67.30 | loss  4.13 | ppl    62.01\n",
      "| epoch   9 | 90/103 batches | lr 0.0000 | ms/batch 66.66 | loss  3.86 | ppl    47.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  7.97s | valid loss  4.94 | valid ppl   139.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 11, learning rate 0.000053 \n",
      "| epoch  10 | 30/103 batches | lr 0.0000 | ms/batch 68.26 | loss  4.51 | ppl    90.55\n",
      "| epoch  10 | 60/103 batches | lr 0.0000 | ms/batch 66.45 | loss  4.17 | ppl    65.02\n",
      "| epoch  10 | 90/103 batches | lr 0.0000 | ms/batch 68.67 | loss  4.04 | ppl    56.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time:  7.95s | valid loss  4.94 | valid ppl   139.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 12, learning rate 0.000052 \n",
      "| epoch  11 | 30/103 batches | lr 0.0000 | ms/batch 67.11 | loss  4.48 | ppl    88.51\n",
      "| epoch  11 | 60/103 batches | lr 0.0000 | ms/batch 66.54 | loss  4.07 | ppl    58.76\n",
      "| epoch  11 | 90/103 batches | lr 0.0000 | ms/batch 66.12 | loss  3.91 | ppl    49.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  8.00s | valid loss  4.94 | valid ppl   139.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 13, learning rate 0.000054 \n",
      "| epoch  12 | 30/103 batches | lr 0.0000 | ms/batch 65.49 | loss  4.56 | ppl    95.15\n",
      "| epoch  12 | 60/103 batches | lr 0.0000 | ms/batch 66.05 | loss  4.11 | ppl    61.04\n",
      "| epoch  12 | 90/103 batches | lr 0.0000 | ms/batch 64.77 | loss  3.93 | ppl    50.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  8.02s | valid loss  4.94 | valid ppl   139.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 14, learning rate 0.000054 \n",
      "| epoch  13 | 30/103 batches | lr 0.0000 | ms/batch 68.49 | loss  4.49 | ppl    89.19\n",
      "| epoch  13 | 60/103 batches | lr 0.0000 | ms/batch 68.75 | loss  4.21 | ppl    67.47\n",
      "| epoch  13 | 90/103 batches | lr 0.0000 | ms/batch 66.31 | loss  4.00 | ppl    54.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  8.00s | valid loss  4.94 | valid ppl   139.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 15, learning rate 0.000053 \n",
      "| epoch  14 | 30/103 batches | lr 0.0000 | ms/batch 68.95 | loss  4.46 | ppl    86.24\n",
      "| epoch  14 | 60/103 batches | lr 0.0000 | ms/batch 67.11 | loss  4.14 | ppl    62.70\n",
      "| epoch  14 | 90/103 batches | lr 0.0000 | ms/batch 66.51 | loss  4.01 | ppl    55.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  8.00s | valid loss  4.94 | valid ppl   139.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 16, learning rate 0.000053 \n",
      "| epoch  15 | 30/103 batches | lr 0.0000 | ms/batch 64.17 | loss  4.47 | ppl    87.11\n",
      "| epoch  15 | 60/103 batches | lr 0.0000 | ms/batch 65.66 | loss  4.15 | ppl    63.48\n",
      "| epoch  15 | 90/103 batches | lr 0.0000 | ms/batch 64.23 | loss  3.94 | ppl    51.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  8.05s | valid loss  4.94 | valid ppl   139.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 17, learning rate 0.000055 \n",
      "| epoch  16 | 30/103 batches | lr 0.0000 | ms/batch 70.04 | loss  4.40 | ppl    81.80\n",
      "| epoch  16 | 60/103 batches | lr 0.0000 | ms/batch 70.66 | loss  4.15 | ppl    63.29\n",
      "| epoch  16 | 90/103 batches | lr 0.0000 | ms/batch 68.91 | loss  4.00 | ppl    54.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  7.96s | valid loss  4.94 | valid ppl   139.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 18, learning rate 0.000051 \n",
      "| epoch  17 | 30/103 batches | lr 0.0000 | ms/batch 66.13 | loss  4.50 | ppl    90.39\n",
      "| epoch  17 | 60/103 batches | lr 0.0000 | ms/batch 64.55 | loss  4.10 | ppl    60.10\n",
      "| epoch  17 | 90/103 batches | lr 0.0000 | ms/batch 67.66 | loss  3.87 | ppl    48.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  8.00s | valid loss  4.94 | valid ppl   139.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 19, learning rate 0.000054 \n",
      "| epoch  18 | 30/103 batches | lr 0.0000 | ms/batch 66.01 | loss  4.50 | ppl    89.67\n",
      "| epoch  18 | 60/103 batches | lr 0.0000 | ms/batch 67.43 | loss  4.03 | ppl    56.14\n",
      "| epoch  18 | 90/103 batches | lr 0.0000 | ms/batch 63.97 | loss  3.85 | ppl    46.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  8.37s | valid loss  4.93 | valid ppl   138.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 20, learning rate 0.000054 \n",
      "| epoch  19 | 30/103 batches | lr 0.0000 | ms/batch 67.77 | loss  4.49 | ppl    89.03\n",
      "| epoch  19 | 60/103 batches | lr 0.0000 | ms/batch 67.60 | loss  4.11 | ppl    61.21\n",
      "| epoch  19 | 90/103 batches | lr 0.0000 | ms/batch 67.50 | loss  3.96 | ppl    52.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  7.94s | valid loss  4.93 | valid ppl   138.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 21, learning rate 0.000052 \n",
      "| epoch  20 | 30/103 batches | lr 0.0000 | ms/batch 67.31 | loss  4.41 | ppl    82.08\n",
      "| epoch  20 | 60/103 batches | lr 0.0000 | ms/batch 68.67 | loss  4.14 | ppl    62.65\n",
      "| epoch  20 | 90/103 batches | lr 0.0000 | ms/batch 68.34 | loss  3.92 | ppl    50.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  7.93s | valid loss  4.93 | valid ppl   139.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 22, learning rate 0.000052 \n",
      "| epoch  21 | 30/103 batches | lr 0.0000 | ms/batch 66.61 | loss  4.43 | ppl    84.04\n",
      "| epoch  21 | 60/103 batches | lr 0.0000 | ms/batch 67.70 | loss  4.05 | ppl    57.33\n",
      "| epoch  21 | 90/103 batches | lr 0.0000 | ms/batch 65.11 | loss  3.82 | ppl    45.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  7.98s | valid loss  4.94 | valid ppl   139.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 23, learning rate 0.000053 \n",
      "| epoch  22 | 30/103 batches | lr 0.0000 | ms/batch 65.94 | loss  4.49 | ppl    88.93\n",
      "| epoch  22 | 60/103 batches | lr 0.0000 | ms/batch 69.66 | loss  4.08 | ppl    59.23\n",
      "| epoch  22 | 90/103 batches | lr 0.0000 | ms/batch 69.11 | loss  3.88 | ppl    48.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  7.95s | valid loss  4.93 | valid ppl   138.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 24, learning rate 0.000052 \n",
      "| epoch  23 | 30/103 batches | lr 0.0000 | ms/batch 66.52 | loss  4.44 | ppl    84.49\n",
      "| epoch  23 | 60/103 batches | lr 0.0000 | ms/batch 67.38 | loss  4.01 | ppl    55.39\n",
      "| epoch  23 | 90/103 batches | lr 0.0000 | ms/batch 66.80 | loss  3.75 | ppl    42.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  7.97s | valid loss  4.93 | valid ppl   138.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 25, learning rate 0.000053 \n",
      "| epoch  24 | 30/103 batches | lr 0.0000 | ms/batch 65.67 | loss  4.47 | ppl    87.21\n",
      "| epoch  24 | 60/103 batches | lr 0.0000 | ms/batch 69.01 | loss  4.08 | ppl    59.08\n",
      "| epoch  24 | 90/103 batches | lr 0.0000 | ms/batch 63.79 | loss  3.81 | ppl    45.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  8.01s | valid loss  4.93 | valid ppl   138.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 26, learning rate 0.000054 \n",
      "| epoch  25 | 30/103 batches | lr 0.0000 | ms/batch 69.01 | loss  4.43 | ppl    84.06\n",
      "| epoch  25 | 60/103 batches | lr 0.0000 | ms/batch 71.76 | loss  4.07 | ppl    58.75\n",
      "| epoch  25 | 90/103 batches | lr 0.0000 | ms/batch 68.87 | loss  3.93 | ppl    50.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  8.17s | valid loss  4.93 | valid ppl   138.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 27, learning rate 0.000053 \n",
      "| epoch  26 | 30/103 batches | lr 0.0000 | ms/batch 68.37 | loss  4.41 | ppl    82.68\n",
      "| epoch  26 | 60/103 batches | lr 0.0000 | ms/batch 64.97 | loss  3.97 | ppl    53.04\n",
      "| epoch  26 | 90/103 batches | lr 0.0000 | ms/batch 65.61 | loss  3.88 | ppl    48.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time:  7.98s | valid loss  4.93 | valid ppl   138.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 28, learning rate 0.000054 \n",
      "| epoch  27 | 30/103 batches | lr 0.0000 | ms/batch 67.46 | loss  4.38 | ppl    79.90\n",
      "| epoch  27 | 60/103 batches | lr 0.0000 | ms/batch 67.29 | loss  4.01 | ppl    55.37\n",
      "| epoch  27 | 90/103 batches | lr 0.0000 | ms/batch 61.97 | loss  3.77 | ppl    43.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time:  8.00s | valid loss  4.93 | valid ppl   138.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 29, learning rate 0.000054 \n",
      "| epoch  28 | 30/103 batches | lr 0.0000 | ms/batch 66.97 | loss  4.38 | ppl    80.04\n",
      "| epoch  28 | 60/103 batches | lr 0.0000 | ms/batch 68.53 | loss  4.03 | ppl    56.36\n",
      "| epoch  28 | 90/103 batches | lr 0.0000 | ms/batch 68.47 | loss  3.82 | ppl    45.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time:  7.96s | valid loss  4.94 | valid ppl   139.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 30, learning rate 0.000052 \n",
      "| epoch  29 | 30/103 batches | lr 0.0000 | ms/batch 66.57 | loss  4.41 | ppl    82.25\n",
      "| epoch  29 | 60/103 batches | lr 0.0000 | ms/batch 67.38 | loss  3.95 | ppl    51.95\n",
      "| epoch  29 | 90/103 batches | lr 0.0000 | ms/batch 67.51 | loss  3.71 | ppl    40.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time:  8.01s | valid loss  4.93 | valid ppl   138.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 31, learning rate 0.000053 \n",
      "| epoch  30 | 30/103 batches | lr 0.0000 | ms/batch 68.22 | loss  4.38 | ppl    79.72\n",
      "| epoch  30 | 60/103 batches | lr 0.0000 | ms/batch 65.76 | loss  3.94 | ppl    51.50\n",
      "| epoch  30 | 90/103 batches | lr 0.0000 | ms/batch 69.18 | loss  3.84 | ppl    46.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time:  8.00s | valid loss  4.93 | valid ppl   138.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 32, learning rate 0.000053 \n",
      "| epoch  31 | 30/103 batches | lr 0.0000 | ms/batch 67.48 | loss  4.36 | ppl    78.06\n",
      "| epoch  31 | 60/103 batches | lr 0.0000 | ms/batch 68.85 | loss  4.03 | ppl    56.39\n",
      "| epoch  31 | 90/103 batches | lr 0.0000 | ms/batch 66.34 | loss  3.85 | ppl    47.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time:  7.96s | valid loss  4.93 | valid ppl   138.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 33, learning rate 0.000052 \n",
      "| epoch  32 | 30/103 batches | lr 0.0000 | ms/batch 65.77 | loss  4.45 | ppl    85.41\n",
      "| epoch  32 | 60/103 batches | lr 0.0000 | ms/batch 66.31 | loss  3.97 | ppl    52.97\n",
      "| epoch  32 | 90/103 batches | lr 0.0000 | ms/batch 66.60 | loss  3.76 | ppl    42.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time:  8.01s | valid loss  4.93 | valid ppl   138.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 34, learning rate 0.000054 \n",
      "| epoch  33 | 30/103 batches | lr 0.0000 | ms/batch 68.05 | loss  4.35 | ppl    77.31\n",
      "| epoch  33 | 60/103 batches | lr 0.0000 | ms/batch 65.51 | loss  3.90 | ppl    49.58\n",
      "| epoch  33 | 90/103 batches | lr 0.0000 | ms/batch 68.30 | loss  3.76 | ppl    42.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time:  7.97s | valid loss  4.93 | valid ppl   138.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 35, learning rate 0.000053 \n",
      "| epoch  34 | 30/103 batches | lr 0.0000 | ms/batch 67.48 | loss  4.33 | ppl    76.08\n",
      "| epoch  34 | 60/103 batches | lr 0.0000 | ms/batch 66.51 | loss  3.91 | ppl    50.00\n",
      "| epoch  34 | 90/103 batches | lr 0.0000 | ms/batch 65.20 | loss  3.75 | ppl    42.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time:  8.03s | valid loss  4.93 | valid ppl   138.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 36, learning rate 0.000054 \n",
      "| epoch  35 | 30/103 batches | lr 0.0000 | ms/batch 66.98 | loss  4.35 | ppl    77.18\n",
      "| epoch  35 | 60/103 batches | lr 0.0000 | ms/batch 67.41 | loss  3.92 | ppl    50.15\n",
      "| epoch  35 | 90/103 batches | lr 0.0000 | ms/batch 65.09 | loss  3.70 | ppl    40.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time:  8.01s | valid loss  4.93 | valid ppl   138.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 37, learning rate 0.000054 \n",
      "| epoch  36 | 30/103 batches | lr 0.0000 | ms/batch 66.78 | loss  4.35 | ppl    77.46\n",
      "| epoch  36 | 60/103 batches | lr 0.0000 | ms/batch 66.04 | loss  3.94 | ppl    51.31\n",
      "| epoch  36 | 90/103 batches | lr 0.0000 | ms/batch 65.92 | loss  3.72 | ppl    41.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time:  8.00s | valid loss  4.93 | valid ppl   138.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 38, learning rate 0.000053 \n",
      "| epoch  37 | 30/103 batches | lr 0.0000 | ms/batch 68.26 | loss  4.37 | ppl    78.81\n",
      "| epoch  37 | 60/103 batches | lr 0.0000 | ms/batch 65.97 | loss  3.89 | ppl    48.99\n",
      "| epoch  37 | 90/103 batches | lr 0.0000 | ms/batch 68.54 | loss  3.77 | ppl    43.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time:  7.98s | valid loss  4.93 | valid ppl   138.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 39, learning rate 0.000053 \n",
      "| epoch  38 | 30/103 batches | lr 0.0000 | ms/batch 68.98 | loss  4.34 | ppl    76.81\n",
      "| epoch  38 | 60/103 batches | lr 0.0000 | ms/batch 67.50 | loss  3.99 | ppl    54.17\n",
      "| epoch  38 | 90/103 batches | lr 0.0000 | ms/batch 68.39 | loss  3.74 | ppl    42.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time:  7.96s | valid loss  4.93 | valid ppl   138.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 40, learning rate 0.000052 \n",
      "| epoch  39 | 30/103 batches | lr 0.0000 | ms/batch 70.18 | loss  4.30 | ppl    73.90\n",
      "| epoch  39 | 60/103 batches | lr 0.0000 | ms/batch 67.28 | loss  4.10 | ppl    60.05\n",
      "| epoch  39 | 90/103 batches | lr 0.0000 | ms/batch 67.44 | loss  3.73 | ppl    41.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time:  7.96s | valid loss  4.93 | valid ppl   138.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 41, learning rate 0.000052 \n",
      "| epoch  40 | 30/103 batches | lr 0.0000 | ms/batch 68.09 | loss  4.33 | ppl    75.68\n",
      "| epoch  40 | 60/103 batches | lr 0.0000 | ms/batch 68.13 | loss  3.94 | ppl    51.56\n",
      "| epoch  40 | 90/103 batches | lr 0.0000 | ms/batch 67.13 | loss  3.76 | ppl    42.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time:  7.96s | valid loss  4.93 | valid ppl   138.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 42, learning rate 0.000052 \n",
      "| epoch  41 | 30/103 batches | lr 0.0000 | ms/batch 67.74 | loss  4.40 | ppl    81.68\n",
      "| epoch  41 | 60/103 batches | lr 0.0000 | ms/batch 65.60 | loss  3.92 | ppl    50.23\n",
      "| epoch  41 | 90/103 batches | lr 0.0000 | ms/batch 67.39 | loss  3.68 | ppl    39.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time:  8.20s | valid loss  4.93 | valid ppl   139.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 43, learning rate 0.000054 \n",
      "| epoch  42 | 30/103 batches | lr 0.0000 | ms/batch 68.80 | loss  4.34 | ppl    76.67\n",
      "| epoch  42 | 60/103 batches | lr 0.0000 | ms/batch 69.25 | loss  3.98 | ppl    53.58\n",
      "| epoch  42 | 90/103 batches | lr 0.0000 | ms/batch 67.02 | loss  3.73 | ppl    41.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time:  8.03s | valid loss  4.93 | valid ppl   138.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 44, learning rate 0.000053 \n",
      "| epoch  43 | 30/103 batches | lr 0.0000 | ms/batch 65.98 | loss  4.40 | ppl    81.31\n",
      "| epoch  43 | 60/103 batches | lr 0.0000 | ms/batch 66.79 | loss  3.91 | ppl    49.98\n",
      "| epoch  43 | 90/103 batches | lr 0.0000 | ms/batch 68.08 | loss  3.65 | ppl    38.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time:  8.06s | valid loss  4.93 | valid ppl   138.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 45, learning rate 0.000054 \n",
      "| epoch  44 | 30/103 batches | lr 0.0000 | ms/batch 67.19 | loss  4.30 | ppl    73.43\n",
      "| epoch  44 | 60/103 batches | lr 0.0000 | ms/batch 66.29 | loss  3.89 | ppl    49.04\n",
      "| epoch  44 | 90/103 batches | lr 0.0000 | ms/batch 67.81 | loss  3.60 | ppl    36.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time:  8.04s | valid loss  4.93 | valid ppl   138.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 46, learning rate 0.000054 \n",
      "| epoch  45 | 30/103 batches | lr 0.0000 | ms/batch 67.45 | loss  4.29 | ppl    73.14\n",
      "| epoch  45 | 60/103 batches | lr 0.0000 | ms/batch 68.03 | loss  3.91 | ppl    50.15\n",
      "| epoch  45 | 90/103 batches | lr 0.0000 | ms/batch 67.17 | loss  3.69 | ppl    39.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time:  7.98s | valid loss  4.93 | valid ppl   138.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 47, learning rate 0.000052 \n",
      "| epoch  46 | 30/103 batches | lr 0.0000 | ms/batch 67.93 | loss  4.32 | ppl    74.96\n",
      "| epoch  46 | 60/103 batches | lr 0.0000 | ms/batch 67.85 | loss  3.90 | ppl    49.17\n",
      "| epoch  46 | 90/103 batches | lr 0.0000 | ms/batch 68.83 | loss  3.64 | ppl    38.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time:  7.98s | valid loss  4.94 | valid ppl   139.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 48, learning rate 0.000052 \n",
      "| epoch  47 | 30/103 batches | lr 0.0000 | ms/batch 68.29 | loss  4.31 | ppl    74.21\n",
      "| epoch  47 | 60/103 batches | lr 0.0000 | ms/batch 68.27 | loss  3.92 | ppl    50.42\n",
      "| epoch  47 | 90/103 batches | lr 0.0000 | ms/batch 68.78 | loss  3.65 | ppl    38.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time:  8.00s | valid loss  4.93 | valid ppl   138.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 49, learning rate 0.000052 \n",
      "| epoch  48 | 30/103 batches | lr 0.0000 | ms/batch 69.30 | loss  4.29 | ppl    72.98\n",
      "| epoch  48 | 60/103 batches | lr 0.0000 | ms/batch 67.14 | loss  3.88 | ppl    48.44\n",
      "| epoch  48 | 90/103 batches | lr 0.0000 | ms/batch 67.43 | loss  3.67 | ppl    39.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time:  8.03s | valid loss  4.93 | valid ppl   138.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 50, learning rate 0.000053 \n",
      "| epoch  49 | 30/103 batches | lr 0.0000 | ms/batch 65.56 | loss  4.35 | ppl    77.12\n",
      "| epoch  49 | 60/103 batches | lr 0.0000 | ms/batch 69.43 | loss  3.82 | ppl    45.69\n",
      "| epoch  49 | 90/103 batches | lr 0.0000 | ms/batch 68.54 | loss  3.63 | ppl    37.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time:  8.05s | valid loss  4.93 | valid ppl   138.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 51, learning rate 0.000053 \n",
      "| epoch  50 | 30/103 batches | lr 0.0000 | ms/batch 69.56 | loss  4.31 | ppl    74.29\n",
      "| epoch  50 | 60/103 batches | lr 0.0000 | ms/batch 69.20 | loss  3.90 | ppl    49.26\n",
      "| epoch  50 | 90/103 batches | lr 0.0000 | ms/batch 67.52 | loss  3.66 | ppl    38.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  8.00s | valid loss  4.93 | valid ppl   138.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 52, learning rate 0.000052 \n",
      "| epoch  51 | 30/103 batches | lr 0.0000 | ms/batch 68.41 | loss  4.29 | ppl    72.96\n",
      "| epoch  51 | 60/103 batches | lr 0.0000 | ms/batch 66.04 | loss  3.78 | ppl    43.99\n",
      "| epoch  51 | 90/103 batches | lr 0.0000 | ms/batch 65.89 | loss  3.60 | ppl    36.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time:  8.03s | valid loss  4.93 | valid ppl   138.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 53, learning rate 0.000053 \n",
      "| epoch  52 | 30/103 batches | lr 0.0000 | ms/batch 67.11 | loss  4.27 | ppl    71.22\n",
      "| epoch  52 | 60/103 batches | lr 0.0000 | ms/batch 68.66 | loss  3.85 | ppl    46.92\n",
      "| epoch  52 | 90/103 batches | lr 0.0000 | ms/batch 69.21 | loss  3.68 | ppl    39.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time:  8.03s | valid loss  4.93 | valid ppl   138.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 54, learning rate 0.000053 \n",
      "| epoch  53 | 30/103 batches | lr 0.0000 | ms/batch 67.11 | loss  4.26 | ppl    70.92\n",
      "| epoch  53 | 60/103 batches | lr 0.0000 | ms/batch 67.78 | loss  3.81 | ppl    45.22\n",
      "| epoch  53 | 90/103 batches | lr 0.0000 | ms/batch 69.09 | loss  3.64 | ppl    38.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time:  8.04s | valid loss  4.93 | valid ppl   138.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 55, learning rate 0.000053 \n",
      "| epoch  54 | 30/103 batches | lr 0.0000 | ms/batch 68.66 | loss  4.29 | ppl    72.65\n",
      "| epoch  54 | 60/103 batches | lr 0.0000 | ms/batch 68.67 | loss  3.83 | ppl    45.96\n",
      "| epoch  54 | 90/103 batches | lr 0.0000 | ms/batch 69.29 | loss  3.61 | ppl    36.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time:  8.06s | valid loss  4.93 | valid ppl   138.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 56, learning rate 0.000052 \n",
      "| epoch  55 | 30/103 batches | lr 0.0000 | ms/batch 67.63 | loss  4.25 | ppl    70.39\n",
      "| epoch  55 | 60/103 batches | lr 0.0000 | ms/batch 66.90 | loss  3.75 | ppl    42.71\n",
      "| epoch  55 | 90/103 batches | lr 0.0000 | ms/batch 66.63 | loss  3.50 | ppl    33.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time:  8.04s | valid loss  4.93 | valid ppl   139.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 57, learning rate 0.000054 \n",
      "| epoch  56 | 30/103 batches | lr 0.0000 | ms/batch 67.45 | loss  4.25 | ppl    70.27\n",
      "| epoch  56 | 60/103 batches | lr 0.0000 | ms/batch 68.38 | loss  3.80 | ppl    44.60\n",
      "| epoch  56 | 90/103 batches | lr 0.0000 | ms/batch 69.90 | loss  3.60 | ppl    36.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time:  8.03s | valid loss  4.94 | valid ppl   139.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 58, learning rate 0.000052 \n",
      "| epoch  57 | 30/103 batches | lr 0.0000 | ms/batch 68.67 | loss  4.25 | ppl    70.41\n",
      "| epoch  57 | 60/103 batches | lr 0.0000 | ms/batch 67.13 | loss  3.74 | ppl    42.27\n",
      "| epoch  57 | 90/103 batches | lr 0.0000 | ms/batch 67.31 | loss  3.47 | ppl    32.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time:  8.08s | valid loss  4.94 | valid ppl   139.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 59, learning rate 0.000054 \n",
      "| epoch  58 | 30/103 batches | lr 0.0000 | ms/batch 66.55 | loss  4.26 | ppl    71.06\n",
      "| epoch  58 | 60/103 batches | lr 0.0000 | ms/batch 68.81 | loss  3.80 | ppl    44.48\n",
      "| epoch  58 | 90/103 batches | lr 0.0000 | ms/batch 67.44 | loss  3.52 | ppl    33.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time:  8.03s | valid loss  4.94 | valid ppl   139.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 60, learning rate 0.000053 \n",
      "| epoch  59 | 30/103 batches | lr 0.0000 | ms/batch 65.75 | loss  4.33 | ppl    75.74\n",
      "| epoch  59 | 60/103 batches | lr 0.0000 | ms/batch 68.00 | loss  3.78 | ppl    43.86\n",
      "| epoch  59 | 90/103 batches | lr 0.0000 | ms/batch 67.92 | loss  3.50 | ppl    33.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time:  8.05s | valid loss  4.94 | valid ppl   139.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 61, learning rate 0.000054 \n",
      "| epoch  60 | 30/103 batches | lr 0.0000 | ms/batch 67.11 | loss  4.23 | ppl    68.54\n",
      "| epoch  60 | 60/103 batches | lr 0.0000 | ms/batch 67.58 | loss  3.77 | ppl    43.42\n",
      "| epoch  60 | 90/103 batches | lr 0.0000 | ms/batch 69.38 | loss  3.62 | ppl    37.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time:  7.98s | valid loss  4.94 | valid ppl   139.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 62, learning rate 0.000052 \n",
      "| epoch  61 | 30/103 batches | lr 0.0000 | ms/batch 68.10 | loss  4.22 | ppl    68.03\n",
      "| epoch  61 | 60/103 batches | lr 0.0000 | ms/batch 67.58 | loss  3.82 | ppl    45.76\n",
      "| epoch  61 | 90/103 batches | lr 0.0000 | ms/batch 67.08 | loss  3.52 | ppl    33.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time:  8.01s | valid loss  4.94 | valid ppl   139.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 63, learning rate 0.000053 \n",
      "| epoch  62 | 30/103 batches | lr 0.0000 | ms/batch 69.02 | loss  4.22 | ppl    67.92\n",
      "| epoch  62 | 60/103 batches | lr 0.0000 | ms/batch 67.19 | loss  3.78 | ppl    43.73\n",
      "| epoch  62 | 90/103 batches | lr 0.0000 | ms/batch 69.81 | loss  3.53 | ppl    34.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time:  8.02s | valid loss  4.94 | valid ppl   139.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 64, learning rate 0.000052 \n",
      "| epoch  63 | 30/103 batches | lr 0.0000 | ms/batch 66.26 | loss  4.25 | ppl    70.22\n",
      "| epoch  63 | 60/103 batches | lr 0.0000 | ms/batch 66.31 | loss  3.73 | ppl    41.67\n",
      "| epoch  63 | 90/103 batches | lr 0.0000 | ms/batch 66.50 | loss  3.51 | ppl    33.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time:  8.04s | valid loss  4.94 | valid ppl   140.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 65, learning rate 0.000054 \n",
      "| epoch  64 | 30/103 batches | lr 0.0000 | ms/batch 64.41 | loss  4.25 | ppl    69.99\n",
      "| epoch  64 | 60/103 batches | lr 0.0000 | ms/batch 68.20 | loss  3.75 | ppl    42.48\n",
      "| epoch  64 | 90/103 batches | lr 0.0000 | ms/batch 68.12 | loss  3.40 | ppl    29.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time:  8.00s | valid loss  4.95 | valid ppl   140.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 66, learning rate 0.000053 \n",
      "| epoch  65 | 30/103 batches | lr 0.0000 | ms/batch 64.84 | loss  4.35 | ppl    77.65\n",
      "| epoch  65 | 60/103 batches | lr 0.0000 | ms/batch 67.91 | loss  3.73 | ppl    41.71\n",
      "| epoch  65 | 90/103 batches | lr 0.0000 | ms/batch 67.93 | loss  3.46 | ppl    31.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time:  8.01s | valid loss  4.94 | valid ppl   139.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 67, learning rate 0.000053 \n",
      "| epoch  66 | 30/103 batches | lr 0.0000 | ms/batch 65.79 | loss  4.34 | ppl    76.67\n",
      "| epoch  66 | 60/103 batches | lr 0.0000 | ms/batch 66.61 | loss  3.72 | ppl    41.13\n",
      "| epoch  66 | 90/103 batches | lr 0.0000 | ms/batch 66.87 | loss  3.48 | ppl    32.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time:  8.03s | valid loss  4.94 | valid ppl   140.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 68, learning rate 0.000054 \n",
      "| epoch  67 | 30/103 batches | lr 0.0000 | ms/batch 69.43 | loss  4.21 | ppl    67.44\n",
      "| epoch  67 | 60/103 batches | lr 0.0000 | ms/batch 66.28 | loss  3.73 | ppl    41.80\n",
      "| epoch  67 | 90/103 batches | lr 0.0000 | ms/batch 67.78 | loss  3.51 | ppl    33.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time:  8.05s | valid loss  4.95 | valid ppl   140.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 69, learning rate 0.000054 \n",
      "| epoch  68 | 30/103 batches | lr 0.0000 | ms/batch 68.44 | loss  4.25 | ppl    69.81\n",
      "| epoch  68 | 60/103 batches | lr 0.0000 | ms/batch 68.99 | loss  3.76 | ppl    42.92\n",
      "| epoch  68 | 90/103 batches | lr 0.0000 | ms/batch 64.30 | loss  3.41 | ppl    30.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time:  8.05s | valid loss  4.94 | valid ppl   140.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 70, learning rate 0.000053 \n",
      "| epoch  69 | 30/103 batches | lr 0.0000 | ms/batch 67.32 | loss  4.19 | ppl    65.95\n",
      "| epoch  69 | 60/103 batches | lr 0.0000 | ms/batch 66.77 | loss  3.68 | ppl    39.57\n",
      "| epoch  69 | 90/103 batches | lr 0.0000 | ms/batch 68.72 | loss  3.43 | ppl    30.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time:  8.03s | valid loss  4.95 | valid ppl   140.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 71, learning rate 0.000053 \n",
      "| epoch  70 | 30/103 batches | lr 0.0000 | ms/batch 70.64 | loss  4.21 | ppl    67.27\n",
      "| epoch  70 | 60/103 batches | lr 0.0000 | ms/batch 67.02 | loss  3.71 | ppl    41.00\n",
      "| epoch  70 | 90/103 batches | lr 0.0000 | ms/batch 67.98 | loss  3.53 | ppl    34.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time:  8.10s | valid loss  4.95 | valid ppl   140.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 72, learning rate 0.000053 \n",
      "| epoch  71 | 30/103 batches | lr 0.0000 | ms/batch 68.31 | loss  4.21 | ppl    67.53\n",
      "| epoch  71 | 60/103 batches | lr 0.0000 | ms/batch 68.58 | loss  3.72 | ppl    41.34\n",
      "| epoch  71 | 90/103 batches | lr 0.0000 | ms/batch 68.67 | loss  3.49 | ppl    32.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time:  8.00s | valid loss  4.95 | valid ppl   140.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 73, learning rate 0.000052 \n",
      "| epoch  72 | 30/103 batches | lr 0.0000 | ms/batch 68.34 | loss  4.18 | ppl    65.59\n",
      "| epoch  72 | 60/103 batches | lr 0.0000 | ms/batch 68.26 | loss  3.69 | ppl    39.97\n",
      "| epoch  72 | 90/103 batches | lr 0.0000 | ms/batch 70.40 | loss  3.48 | ppl    32.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time:  8.00s | valid loss  4.95 | valid ppl   140.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 74, learning rate 0.000052 \n",
      "| epoch  73 | 30/103 batches | lr 0.0000 | ms/batch 67.75 | loss  4.25 | ppl    70.11\n",
      "| epoch  73 | 60/103 batches | lr 0.0000 | ms/batch 66.09 | loss  3.67 | ppl    39.28\n",
      "| epoch  73 | 90/103 batches | lr 0.0000 | ms/batch 67.10 | loss  3.41 | ppl    30.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time:  8.04s | valid loss  4.95 | valid ppl   140.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 75, learning rate 0.000054 \n",
      "| epoch  74 | 30/103 batches | lr 0.0000 | ms/batch 65.40 | loss  4.26 | ppl    70.75\n",
      "| epoch  74 | 60/103 batches | lr 0.0000 | ms/batch 70.42 | loss  3.71 | ppl    40.69\n",
      "| epoch  74 | 90/103 batches | lr 0.0000 | ms/batch 68.60 | loss  3.49 | ppl    32.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time:  8.00s | valid loss  4.95 | valid ppl   141.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 76, learning rate 0.000052 \n",
      "| epoch  75 | 30/103 batches | lr 0.0000 | ms/batch 67.69 | loss  4.16 | ppl    64.19\n",
      "| epoch  75 | 60/103 batches | lr 0.0000 | ms/batch 67.37 | loss  3.67 | ppl    39.20\n",
      "| epoch  75 | 90/103 batches | lr 0.0000 | ms/batch 69.45 | loss  3.50 | ppl    33.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time:  8.00s | valid loss  4.95 | valid ppl   141.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 77, learning rate 0.000052 \n",
      "| epoch  76 | 30/103 batches | lr 0.0000 | ms/batch 68.30 | loss  4.15 | ppl    63.43\n",
      "| epoch  76 | 60/103 batches | lr 0.0000 | ms/batch 65.61 | loss  3.68 | ppl    39.71\n",
      "| epoch  76 | 90/103 batches | lr 0.0000 | ms/batch 66.64 | loss  3.39 | ppl    29.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time:  8.04s | valid loss  4.95 | valid ppl   141.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 78, learning rate 0.000053 \n",
      "| epoch  77 | 30/103 batches | lr 0.0000 | ms/batch 67.83 | loss  4.14 | ppl    63.03\n",
      "| epoch  77 | 60/103 batches | lr 0.0000 | ms/batch 68.49 | loss  3.66 | ppl    38.81\n",
      "| epoch  77 | 90/103 batches | lr 0.0000 | ms/batch 67.82 | loss  3.50 | ppl    32.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time:  8.01s | valid loss  4.95 | valid ppl   141.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 79, learning rate 0.000053 \n",
      "| epoch  78 | 30/103 batches | lr 0.0000 | ms/batch 66.82 | loss  4.18 | ppl    65.42\n",
      "| epoch  78 | 60/103 batches | lr 0.0000 | ms/batch 67.85 | loss  3.61 | ppl    36.79\n",
      "| epoch  78 | 90/103 batches | lr 0.0000 | ms/batch 68.11 | loss  3.35 | ppl    28.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time:  8.03s | valid loss  4.95 | valid ppl   141.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 80, learning rate 0.000053 \n",
      "| epoch  79 | 30/103 batches | lr 0.0000 | ms/batch 67.88 | loss  4.16 | ppl    63.80\n",
      "| epoch  79 | 60/103 batches | lr 0.0000 | ms/batch 69.47 | loss  3.61 | ppl    37.01\n",
      "| epoch  79 | 90/103 batches | lr 0.0000 | ms/batch 70.40 | loss  3.41 | ppl    30.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time:  8.17s | valid loss  4.96 | valid ppl   142.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 81, learning rate 0.000053 \n",
      "| epoch  80 | 30/103 batches | lr 0.0000 | ms/batch 64.19 | loss  4.15 | ppl    63.33\n",
      "| epoch  80 | 60/103 batches | lr 0.0000 | ms/batch 64.46 | loss  3.64 | ppl    38.23\n",
      "| epoch  80 | 90/103 batches | lr 0.0000 | ms/batch 69.08 | loss  3.37 | ppl    29.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time:  8.04s | valid loss  4.96 | valid ppl   141.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 82, learning rate 0.000054 \n",
      "| epoch  81 | 30/103 batches | lr 0.0000 | ms/batch 66.98 | loss  4.12 | ppl    61.63\n",
      "| epoch  81 | 60/103 batches | lr 0.0000 | ms/batch 69.65 | loss  3.66 | ppl    38.85\n",
      "| epoch  81 | 90/103 batches | lr 0.0000 | ms/batch 68.92 | loss  3.44 | ppl    31.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time:  8.04s | valid loss  4.96 | valid ppl   143.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 83, learning rate 0.000053 \n",
      "| epoch  82 | 30/103 batches | lr 0.0000 | ms/batch 65.01 | loss  4.17 | ppl    64.42\n",
      "| epoch  82 | 60/103 batches | lr 0.0000 | ms/batch 66.96 | loss  3.61 | ppl    37.00\n",
      "| epoch  82 | 90/103 batches | lr 0.0000 | ms/batch 67.22 | loss  3.37 | ppl    29.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time:  8.05s | valid loss  4.96 | valid ppl   142.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 84, learning rate 0.000054 \n",
      "| epoch  83 | 30/103 batches | lr 0.0000 | ms/batch 66.56 | loss  4.20 | ppl    66.40\n",
      "| epoch  83 | 60/103 batches | lr 0.0000 | ms/batch 66.15 | loss  3.62 | ppl    37.45\n",
      "| epoch  83 | 90/103 batches | lr 0.0000 | ms/batch 65.48 | loss  3.36 | ppl    28.73\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time:  8.07s | valid loss  4.96 | valid ppl   142.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 85, learning rate 0.000054 \n",
      "| epoch  84 | 30/103 batches | lr 0.0000 | ms/batch 68.23 | loss  4.13 | ppl    62.27\n",
      "| epoch  84 | 60/103 batches | lr 0.0000 | ms/batch 70.41 | loss  3.67 | ppl    39.37\n",
      "| epoch  84 | 90/103 batches | lr 0.0000 | ms/batch 70.92 | loss  3.42 | ppl    30.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time:  8.20s | valid loss  4.96 | valid ppl   142.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 86, learning rate 0.000052 \n",
      "| epoch  85 | 30/103 batches | lr 0.0000 | ms/batch 69.68 | loss  4.14 | ppl    62.84\n",
      "| epoch  85 | 60/103 batches | lr 0.0000 | ms/batch 69.15 | loss  3.68 | ppl    39.58\n",
      "| epoch  85 | 90/103 batches | lr 0.0000 | ms/batch 69.13 | loss  3.37 | ppl    29.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time:  8.05s | valid loss  4.97 | valid ppl   143.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 87, learning rate 0.000053 \n",
      "| epoch  86 | 30/103 batches | lr 0.0000 | ms/batch 68.65 | loss  4.12 | ppl    61.81\n",
      "| epoch  86 | 60/103 batches | lr 0.0000 | ms/batch 67.78 | loss  3.62 | ppl    37.30\n",
      "| epoch  86 | 90/103 batches | lr 0.0000 | ms/batch 66.36 | loss  3.30 | ppl    26.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time:  8.06s | valid loss  4.97 | valid ppl   143.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 88, learning rate 0.000053 \n",
      "| epoch  87 | 30/103 batches | lr 0.0000 | ms/batch 67.60 | loss  4.11 | ppl    61.22\n",
      "| epoch  87 | 60/103 batches | lr 0.0000 | ms/batch 64.15 | loss  3.60 | ppl    36.45\n",
      "| epoch  87 | 90/103 batches | lr 0.0000 | ms/batch 66.25 | loss  3.33 | ppl    28.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time:  8.10s | valid loss  4.96 | valid ppl   143.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 89, learning rate 0.000055 \n",
      "| epoch  88 | 30/103 batches | lr 0.0000 | ms/batch 69.85 | loss  4.10 | ppl    60.52\n",
      "| epoch  88 | 60/103 batches | lr 0.0000 | ms/batch 67.76 | loss  3.63 | ppl    37.64\n",
      "| epoch  88 | 90/103 batches | lr 0.0000 | ms/batch 67.87 | loss  3.34 | ppl    28.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time:  8.00s | valid loss  4.97 | valid ppl   143.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 90, learning rate 0.000052 \n",
      "| epoch  89 | 30/103 batches | lr 0.0000 | ms/batch 68.26 | loss  4.10 | ppl    60.61\n",
      "| epoch  89 | 60/103 batches | lr 0.0000 | ms/batch 69.48 | loss  3.65 | ppl    38.51\n",
      "| epoch  89 | 90/103 batches | lr 0.0000 | ms/batch 68.25 | loss  3.34 | ppl    28.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time:  8.01s | valid loss  4.97 | valid ppl   143.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 91, learning rate 0.000052 \n",
      "| epoch  90 | 30/103 batches | lr 0.0000 | ms/batch 67.20 | loss  4.11 | ppl    61.03\n",
      "| epoch  90 | 60/103 batches | lr 0.0000 | ms/batch 67.61 | loss  3.56 | ppl    35.16\n",
      "| epoch  90 | 90/103 batches | lr 0.0000 | ms/batch 66.98 | loss  3.24 | ppl    25.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time:  8.07s | valid loss  4.98 | valid ppl   146.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 92, learning rate 0.000054 \n",
      "| epoch  91 | 30/103 batches | lr 0.0000 | ms/batch 67.11 | loss  4.13 | ppl    62.25\n",
      "| epoch  91 | 60/103 batches | lr 0.0000 | ms/batch 67.94 | loss  3.55 | ppl    34.72\n",
      "| epoch  91 | 90/103 batches | lr 0.0000 | ms/batch 67.85 | loss  3.27 | ppl    26.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time:  8.05s | valid loss  4.97 | valid ppl   144.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 93, learning rate 0.000053 \n",
      "| epoch  92 | 30/103 batches | lr 0.0000 | ms/batch 69.14 | loss  4.11 | ppl    61.15\n",
      "| epoch  92 | 60/103 batches | lr 0.0000 | ms/batch 68.58 | loss  3.60 | ppl    36.57\n",
      "| epoch  92 | 90/103 batches | lr 0.0000 | ms/batch 69.34 | loss  3.30 | ppl    27.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time:  8.03s | valid loss  4.97 | valid ppl   144.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 94, learning rate 0.000053 \n",
      "| epoch  93 | 30/103 batches | lr 0.0000 | ms/batch 68.14 | loss  4.08 | ppl    59.09\n",
      "| epoch  93 | 60/103 batches | lr 0.0000 | ms/batch 71.36 | loss  3.62 | ppl    37.17\n",
      "| epoch  93 | 90/103 batches | lr 0.0000 | ms/batch 69.46 | loss  3.32 | ppl    27.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time:  8.01s | valid loss  4.98 | valid ppl   144.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 95, learning rate 0.000052 \n",
      "| epoch  94 | 30/103 batches | lr 0.0000 | ms/batch 69.34 | loss  4.10 | ppl    60.36\n",
      "| epoch  94 | 60/103 batches | lr 0.0000 | ms/batch 66.98 | loss  3.58 | ppl    35.72\n",
      "| epoch  94 | 90/103 batches | lr 0.0000 | ms/batch 68.39 | loss  3.38 | ppl    29.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time:  8.03s | valid loss  4.98 | valid ppl   145.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 96, learning rate 0.000053 \n",
      "| epoch  95 | 30/103 batches | lr 0.0000 | ms/batch 66.58 | loss  4.14 | ppl    63.00\n",
      "| epoch  95 | 60/103 batches | lr 0.0000 | ms/batch 69.61 | loss  3.57 | ppl    35.35\n",
      "| epoch  95 | 90/103 batches | lr 0.0000 | ms/batch 68.63 | loss  3.35 | ppl    28.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time:  8.04s | valid loss  4.98 | valid ppl   145.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 97, learning rate 0.000053 \n",
      "| epoch  96 | 30/103 batches | lr 0.0000 | ms/batch 65.64 | loss  4.27 | ppl    71.76\n",
      "| epoch  96 | 60/103 batches | lr 0.0000 | ms/batch 67.70 | loss  3.55 | ppl    34.77\n",
      "| epoch  96 | 90/103 batches | lr 0.0000 | ms/batch 66.29 | loss  3.25 | ppl    25.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time:  8.03s | valid loss  4.98 | valid ppl   145.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 98, learning rate 0.000054 \n",
      "| epoch  97 | 30/103 batches | lr 0.0000 | ms/batch 66.09 | loss  4.14 | ppl    62.52\n",
      "| epoch  97 | 60/103 batches | lr 0.0000 | ms/batch 68.35 | loss  3.50 | ppl    32.96\n",
      "| epoch  97 | 90/103 batches | lr 0.0000 | ms/batch 69.43 | loss  3.36 | ppl    28.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time:  8.00s | valid loss  4.98 | valid ppl   145.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 99, learning rate 0.000053 \n",
      "| epoch  98 | 30/103 batches | lr 0.0000 | ms/batch 65.92 | loss  4.15 | ppl    63.69\n",
      "| epoch  98 | 60/103 batches | lr 0.0000 | ms/batch 68.08 | loss  3.49 | ppl    32.88\n",
      "| epoch  98 | 90/103 batches | lr 0.0000 | ms/batch 68.42 | loss  3.22 | ppl    24.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time:  8.04s | valid loss  5.00 | valid ppl   148.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 100, learning rate 0.000053 \n",
      "| epoch  99 | 30/103 batches | lr 0.0000 | ms/batch 67.92 | loss  4.06 | ppl    57.77\n",
      "| epoch  99 | 60/103 batches | lr 0.0000 | ms/batch 69.70 | loss  3.58 | ppl    35.98\n",
      "| epoch  99 | 90/103 batches | lr 0.0000 | ms/batch 65.65 | loss  3.28 | ppl    26.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time:  8.04s | valid loss  4.99 | valid ppl   147.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 101, learning rate 0.000053 \n",
      "| epoch 100 | 30/103 batches | lr 0.0000 | ms/batch 68.14 | loss  4.08 | ppl    58.97\n",
      "| epoch 100 | 60/103 batches | lr 0.0000 | ms/batch 68.94 | loss  3.55 | ppl    34.76\n",
      "| epoch 100 | 90/103 batches | lr 0.0000 | ms/batch 70.15 | loss  3.28 | ppl    26.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  7.98s | valid loss  4.99 | valid ppl   147.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 102, learning rate 0.000052 \n",
      "| epoch 101 | 30/103 batches | lr 0.0000 | ms/batch 67.30 | loss  4.06 | ppl    58.02\n",
      "| epoch 101 | 60/103 batches | lr 0.0000 | ms/batch 69.50 | loss  3.53 | ppl    34.07\n",
      "| epoch 101 | 90/103 batches | lr 0.0000 | ms/batch 68.14 | loss  3.26 | ppl    25.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 101 | time:  8.00s | valid loss  5.00 | valid ppl   147.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 103, learning rate 0.000053 \n",
      "| epoch 102 | 30/103 batches | lr 0.0000 | ms/batch 67.18 | loss  4.07 | ppl    58.63\n",
      "| epoch 102 | 60/103 batches | lr 0.0000 | ms/batch 65.88 | loss  3.52 | ppl    33.95\n",
      "| epoch 102 | 90/103 batches | lr 0.0000 | ms/batch 66.22 | loss  3.21 | ppl    24.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 102 | time:  8.05s | valid loss  4.99 | valid ppl   147.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 104, learning rate 0.000054 \n",
      "| epoch 103 | 30/103 batches | lr 0.0000 | ms/batch 66.81 | loss  4.06 | ppl    58.03\n",
      "| epoch 103 | 60/103 batches | lr 0.0000 | ms/batch 69.66 | loss  3.50 | ppl    33.09\n",
      "| epoch 103 | 90/103 batches | lr 0.0000 | ms/batch 64.40 | loss  3.19 | ppl    24.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 103 | time:  8.01s | valid loss  4.99 | valid ppl   147.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 105, learning rate 0.000053 \n",
      "| epoch 104 | 30/103 batches | lr 0.0000 | ms/batch 66.91 | loss  4.06 | ppl    57.99\n",
      "| epoch 104 | 60/103 batches | lr 0.0000 | ms/batch 69.49 | loss  3.50 | ppl    33.16\n",
      "| epoch 104 | 90/103 batches | lr 0.0000 | ms/batch 65.63 | loss  3.21 | ppl    24.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 104 | time:  8.00s | valid loss  4.99 | valid ppl   147.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 106, learning rate 0.000053 \n",
      "| epoch 105 | 30/103 batches | lr 0.0000 | ms/batch 66.51 | loss  4.17 | ppl    64.62\n",
      "| epoch 105 | 60/103 batches | lr 0.0000 | ms/batch 65.57 | loss  3.48 | ppl    32.58\n",
      "| epoch 105 | 90/103 batches | lr 0.0000 | ms/batch 67.18 | loss  3.26 | ppl    25.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 105 | time:  8.04s | valid loss  5.00 | valid ppl   147.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 107, learning rate 0.000054 \n",
      "| epoch 106 | 30/103 batches | lr 0.0000 | ms/batch 65.63 | loss  4.13 | ppl    61.95\n",
      "| epoch 106 | 60/103 batches | lr 0.0000 | ms/batch 67.55 | loss  3.49 | ppl    32.73\n",
      "| epoch 106 | 90/103 batches | lr 0.0000 | ms/batch 69.10 | loss  3.17 | ppl    23.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 106 | time:  8.00s | valid loss  5.00 | valid ppl   148.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 108, learning rate 0.000053 \n",
      "| epoch 107 | 30/103 batches | lr 0.0000 | ms/batch 64.71 | loss  4.10 | ppl    60.40\n",
      "| epoch 107 | 60/103 batches | lr 0.0000 | ms/batch 67.74 | loss  3.49 | ppl    32.76\n",
      "| epoch 107 | 90/103 batches | lr 0.0000 | ms/batch 67.21 | loss  3.28 | ppl    26.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 107 | time:  8.03s | valid loss  5.00 | valid ppl   148.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 109, learning rate 0.000054 \n",
      "| epoch 108 | 30/103 batches | lr 0.0000 | ms/batch 66.73 | loss  4.03 | ppl    56.07\n",
      "| epoch 108 | 60/103 batches | lr 0.0000 | ms/batch 67.26 | loss  3.44 | ppl    31.21\n",
      "| epoch 108 | 90/103 batches | lr 0.0000 | ms/batch 67.01 | loss  3.11 | ppl    22.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 108 | time:  8.02s | valid loss  5.00 | valid ppl   148.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 110, learning rate 0.000053 \n",
      "| epoch 109 | 30/103 batches | lr 0.0000 | ms/batch 69.26 | loss  4.04 | ppl    56.62\n",
      "| epoch 109 | 60/103 batches | lr 0.0000 | ms/batch 67.85 | loss  3.45 | ppl    31.61\n",
      "| epoch 109 | 90/103 batches | lr 0.0000 | ms/batch 68.53 | loss  3.23 | ppl    25.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 109 | time:  8.03s | valid loss  5.01 | valid ppl   149.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 111, learning rate 0.000052 \n",
      "| epoch 110 | 30/103 batches | lr 0.0000 | ms/batch 67.09 | loss  4.03 | ppl    56.10\n",
      "| epoch 110 | 60/103 batches | lr 0.0000 | ms/batch 67.72 | loss  3.43 | ppl    30.79\n",
      "| epoch 110 | 90/103 batches | lr 0.0000 | ms/batch 68.09 | loss  3.13 | ppl    22.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 110 | time:  8.03s | valid loss  5.01 | valid ppl   149.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 112, learning rate 0.000053 \n",
      "| epoch 111 | 30/103 batches | lr 0.0000 | ms/batch 68.91 | loss  4.06 | ppl    57.83\n",
      "| epoch 111 | 60/103 batches | lr 0.0000 | ms/batch 67.39 | loss  3.47 | ppl    32.26\n",
      "| epoch 111 | 90/103 batches | lr 0.0000 | ms/batch 67.38 | loss  3.15 | ppl    23.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 111 | time:  8.05s | valid loss  5.01 | valid ppl   149.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 113, learning rate 0.000053 \n",
      "| epoch 112 | 30/103 batches | lr 0.0000 | ms/batch 68.81 | loss  4.02 | ppl    55.81\n",
      "| epoch 112 | 60/103 batches | lr 0.0000 | ms/batch 66.62 | loss  3.44 | ppl    31.03\n",
      "| epoch 112 | 90/103 batches | lr 0.0000 | ms/batch 67.19 | loss  3.08 | ppl    21.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 112 | time:  8.05s | valid loss  5.01 | valid ppl   149.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 114, learning rate 0.000053 \n",
      "| epoch 113 | 30/103 batches | lr 0.0000 | ms/batch 68.15 | loss  4.01 | ppl    55.42\n",
      "| epoch 113 | 60/103 batches | lr 0.0000 | ms/batch 68.07 | loss  3.42 | ppl    30.62\n",
      "| epoch 113 | 90/103 batches | lr 0.0000 | ms/batch 68.02 | loss  3.21 | ppl    24.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 113 | time:  8.00s | valid loss  5.03 | valid ppl   152.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 115, learning rate 0.000053 \n",
      "| epoch 114 | 30/103 batches | lr 0.0000 | ms/batch 69.83 | loss  4.01 | ppl    55.40\n",
      "| epoch 114 | 60/103 batches | lr 0.0000 | ms/batch 66.80 | loss  3.46 | ppl    31.79\n",
      "| epoch 114 | 90/103 batches | lr 0.0000 | ms/batch 68.32 | loss  3.19 | ppl    24.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 114 | time:  8.02s | valid loss  5.01 | valid ppl   150.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 116, learning rate 0.000053 \n",
      "| epoch 115 | 30/103 batches | lr 0.0000 | ms/batch 68.01 | loss  4.00 | ppl    54.68\n",
      "| epoch 115 | 60/103 batches | lr 0.0000 | ms/batch 69.84 | loss  3.51 | ppl    33.31\n",
      "| epoch 115 | 90/103 batches | lr 0.0000 | ms/batch 67.76 | loss  3.18 | ppl    24.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 115 | time:  7.97s | valid loss  5.02 | valid ppl   150.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 117, learning rate 0.000052 \n",
      "| epoch 116 | 30/103 batches | lr 0.0000 | ms/batch 65.46 | loss  4.11 | ppl    60.88\n",
      "| epoch 116 | 60/103 batches | lr 0.0000 | ms/batch 65.29 | loss  3.44 | ppl    31.30\n",
      "| epoch 116 | 90/103 batches | lr 0.0000 | ms/batch 66.85 | loss  3.11 | ppl    22.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 116 | time:  8.05s | valid loss  5.02 | valid ppl   150.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 118, learning rate 0.000054 \n",
      "| epoch 117 | 30/103 batches | lr 0.0000 | ms/batch 66.60 | loss  4.03 | ppl    56.32\n",
      "| epoch 117 | 60/103 batches | lr 0.0000 | ms/batch 68.60 | loss  3.42 | ppl    30.58\n",
      "| epoch 117 | 90/103 batches | lr 0.0000 | ms/batch 66.46 | loss  3.07 | ppl    21.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 117 | time:  8.01s | valid loss  5.02 | valid ppl   151.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 119, learning rate 0.000053 \n",
      "| epoch 118 | 30/103 batches | lr 0.0000 | ms/batch 67.74 | loss  3.98 | ppl    53.39\n",
      "| epoch 118 | 60/103 batches | lr 0.0000 | ms/batch 66.22 | loss  3.37 | ppl    29.03\n",
      "| epoch 118 | 90/103 batches | lr 0.0000 | ms/batch 67.93 | loss  3.06 | ppl    21.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 118 | time:  8.00s | valid loss  5.02 | valid ppl   151.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 120, learning rate 0.000053 \n",
      "| epoch 119 | 30/103 batches | lr 0.0000 | ms/batch 67.52 | loss  3.99 | ppl    53.97\n",
      "| epoch 119 | 60/103 batches | lr 0.0000 | ms/batch 68.38 | loss  3.40 | ppl    29.83\n",
      "| epoch 119 | 90/103 batches | lr 0.0000 | ms/batch 68.24 | loss  3.17 | ppl    23.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 119 | time:  7.98s | valid loss  5.02 | valid ppl   152.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 121, learning rate 0.000052 \n",
      "| epoch 120 | 30/103 batches | lr 0.0000 | ms/batch 66.80 | loss  3.98 | ppl    53.42\n",
      "| epoch 120 | 60/103 batches | lr 0.0000 | ms/batch 66.63 | loss  3.40 | ppl    29.99\n",
      "| epoch 120 | 90/103 batches | lr 0.0000 | ms/batch 67.38 | loss  3.04 | ppl    20.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 120 | time:  8.07s | valid loss  5.03 | valid ppl   152.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 122, learning rate 0.000053 \n",
      "| epoch 121 | 30/103 batches | lr 0.0000 | ms/batch 68.10 | loss  3.99 | ppl    53.92\n",
      "| epoch 121 | 60/103 batches | lr 0.0000 | ms/batch 66.80 | loss  3.41 | ppl    30.39\n",
      "| epoch 121 | 90/103 batches | lr 0.0000 | ms/batch 67.48 | loss  3.15 | ppl    23.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 121 | time:  7.98s | valid loss  5.03 | valid ppl   152.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 123, learning rate 0.000053 \n",
      "| epoch 122 | 30/103 batches | lr 0.0000 | ms/batch 68.19 | loss  3.98 | ppl    53.55\n",
      "| epoch 122 | 60/103 batches | lr 0.0000 | ms/batch 69.39 | loss  3.45 | ppl    31.49\n",
      "| epoch 122 | 90/103 batches | lr 0.0000 | ms/batch 67.78 | loss  3.10 | ppl    22.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 122 | time:  7.99s | valid loss  5.03 | valid ppl   153.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 124, learning rate 0.000052 \n",
      "| epoch 123 | 30/103 batches | lr 0.0000 | ms/batch 70.35 | loss  3.98 | ppl    53.32\n",
      "| epoch 123 | 60/103 batches | lr 0.0000 | ms/batch 73.17 | loss  3.44 | ppl    31.14\n",
      "| epoch 123 | 90/103 batches | lr 0.0000 | ms/batch 66.75 | loss  3.27 | ppl    26.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 123 | time:  8.19s | valid loss  5.04 | valid ppl   154.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 125, learning rate 0.000053 \n",
      "| epoch 124 | 30/103 batches | lr 0.0000 | ms/batch 68.76 | loss  3.99 | ppl    54.08\n",
      "| epoch 124 | 60/103 batches | lr 0.0000 | ms/batch 67.79 | loss  3.37 | ppl    29.02\n",
      "| epoch 124 | 90/103 batches | lr 0.0000 | ms/batch 66.74 | loss  3.12 | ppl    22.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 124 | time:  8.00s | valid loss  5.03 | valid ppl   153.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 126, learning rate 0.000053 \n",
      "| epoch 125 | 30/103 batches | lr 0.0000 | ms/batch 66.66 | loss  3.97 | ppl    52.86\n",
      "| epoch 125 | 60/103 batches | lr 0.0000 | ms/batch 66.58 | loss  3.35 | ppl    28.42\n",
      "| epoch 125 | 90/103 batches | lr 0.0000 | ms/batch 68.02 | loss  3.02 | ppl    20.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 125 | time:  8.00s | valid loss  5.03 | valid ppl   153.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 127, learning rate 0.000053 \n",
      "| epoch 126 | 30/103 batches | lr 0.0000 | ms/batch 65.25 | loss  4.06 | ppl    57.81\n",
      "| epoch 126 | 60/103 batches | lr 0.0000 | ms/batch 64.70 | loss  3.38 | ppl    29.41\n",
      "| epoch 126 | 90/103 batches | lr 0.0000 | ms/batch 67.39 | loss  3.03 | ppl    20.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 126 | time:  8.00s | valid loss  5.04 | valid ppl   154.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 128, learning rate 0.000054 \n",
      "| epoch 127 | 30/103 batches | lr 0.0000 | ms/batch 68.00 | loss  3.95 | ppl    52.03\n",
      "| epoch 127 | 60/103 batches | lr 0.0000 | ms/batch 68.08 | loss  3.34 | ppl    28.14\n",
      "| epoch 127 | 90/103 batches | lr 0.0000 | ms/batch 67.49 | loss  3.10 | ppl    22.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 127 | time:  8.00s | valid loss  5.04 | valid ppl   154.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 129, learning rate 0.000053 \n",
      "| epoch 128 | 30/103 batches | lr 0.0000 | ms/batch 68.62 | loss  3.97 | ppl    52.77\n",
      "| epoch 128 | 60/103 batches | lr 0.0000 | ms/batch 66.03 | loss  3.34 | ppl    28.32\n",
      "| epoch 128 | 90/103 batches | lr 0.0000 | ms/batch 68.85 | loss  3.11 | ppl    22.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 128 | time:  7.98s | valid loss  5.04 | valid ppl   154.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 130, learning rate 0.000052 \n",
      "| epoch 129 | 30/103 batches | lr 0.0000 | ms/batch 66.60 | loss  3.95 | ppl    52.18\n",
      "| epoch 129 | 60/103 batches | lr 0.0000 | ms/batch 67.82 | loss  3.34 | ppl    28.19\n",
      "| epoch 129 | 90/103 batches | lr 0.0000 | ms/batch 64.64 | loss  3.03 | ppl    20.73\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 129 | time:  8.01s | valid loss  5.04 | valid ppl   154.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 131, learning rate 0.000054 \n",
      "| epoch 130 | 30/103 batches | lr 0.0000 | ms/batch 68.19 | loss  3.95 | ppl    51.98\n",
      "| epoch 130 | 60/103 batches | lr 0.0000 | ms/batch 67.41 | loss  3.36 | ppl    28.68\n",
      "| epoch 130 | 90/103 batches | lr 0.0000 | ms/batch 68.28 | loss  3.09 | ppl    22.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 130 | time:  8.02s | valid loss  5.06 | valid ppl   158.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 132, learning rate 0.000053 \n",
      "| epoch 131 | 30/103 batches | lr 0.0000 | ms/batch 66.33 | loss  4.02 | ppl    55.82\n",
      "| epoch 131 | 60/103 batches | lr 0.0000 | ms/batch 68.45 | loss  3.33 | ppl    28.05\n",
      "| epoch 131 | 90/103 batches | lr 0.0000 | ms/batch 70.69 | loss  3.05 | ppl    21.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 131 | time:  7.97s | valid loss  5.05 | valid ppl   155.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 133, learning rate 0.000052 \n",
      "| epoch 132 | 30/103 batches | lr 0.0000 | ms/batch 67.70 | loss  3.93 | ppl    51.16\n",
      "| epoch 132 | 60/103 batches | lr 0.0000 | ms/batch 68.54 | loss  3.32 | ppl    27.66\n",
      "| epoch 132 | 90/103 batches | lr 0.0000 | ms/batch 65.92 | loss  3.00 | ppl    19.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 132 | time:  8.01s | valid loss  5.05 | valid ppl   155.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 134, learning rate 0.000053 \n",
      "| epoch 133 | 30/103 batches | lr 0.0000 | ms/batch 68.93 | loss  3.93 | ppl    51.00\n",
      "| epoch 133 | 60/103 batches | lr 0.0000 | ms/batch 66.98 | loss  3.32 | ppl    27.65\n",
      "| epoch 133 | 90/103 batches | lr 0.0000 | ms/batch 67.40 | loss  3.06 | ppl    21.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 133 | time:  8.00s | valid loss  5.05 | valid ppl   155.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 135, learning rate 0.000053 \n",
      "| epoch 134 | 30/103 batches | lr 0.0000 | ms/batch 68.75 | loss  3.93 | ppl    50.68\n",
      "| epoch 134 | 60/103 batches | lr 0.0000 | ms/batch 63.27 | loss  3.33 | ppl    28.05\n",
      "| epoch 134 | 90/103 batches | lr 0.0000 | ms/batch 66.51 | loss  2.99 | ppl    19.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 134 | time:  8.04s | valid loss  5.05 | valid ppl   156.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 136, learning rate 0.000054 \n",
      "| epoch 135 | 30/103 batches | lr 0.0000 | ms/batch 66.54 | loss  3.97 | ppl    52.76\n",
      "| epoch 135 | 60/103 batches | lr 0.0000 | ms/batch 68.66 | loss  3.33 | ppl    27.88\n",
      "| epoch 135 | 90/103 batches | lr 0.0000 | ms/batch 67.62 | loss  3.07 | ppl    21.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 135 | time:  8.02s | valid loss  5.05 | valid ppl   156.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 137, learning rate 0.000053 \n",
      "| epoch 136 | 30/103 batches | lr 0.0000 | ms/batch 66.90 | loss  3.93 | ppl    51.07\n",
      "| epoch 136 | 60/103 batches | lr 0.0000 | ms/batch 65.12 | loss  3.42 | ppl    30.61\n",
      "| epoch 136 | 90/103 batches | lr 0.0000 | ms/batch 66.52 | loss  2.96 | ppl    19.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 136 | time:  8.00s | valid loss  5.06 | valid ppl   156.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 138, learning rate 0.000054 \n",
      "| epoch 137 | 30/103 batches | lr 0.0000 | ms/batch 67.42 | loss  3.93 | ppl    50.79\n",
      "| epoch 137 | 60/103 batches | lr 0.0000 | ms/batch 66.28 | loss  3.27 | ppl    26.26\n",
      "| epoch 137 | 90/103 batches | lr 0.0000 | ms/batch 69.14 | loss  3.07 | ppl    21.47\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 137 | time:  7.94s | valid loss  5.06 | valid ppl   157.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 139, learning rate 0.000052 \n",
      "| epoch 138 | 30/103 batches | lr 0.0000 | ms/batch 64.37 | loss  4.04 | ppl    56.98\n",
      "| epoch 138 | 60/103 batches | lr 0.0000 | ms/batch 65.85 | loss  3.31 | ppl    27.34\n",
      "| epoch 138 | 90/103 batches | lr 0.0000 | ms/batch 69.14 | loss  2.94 | ppl    18.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 138 | time:  8.01s | valid loss  5.06 | valid ppl   157.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 140, learning rate 0.000054 \n",
      "| epoch 139 | 30/103 batches | lr 0.0000 | ms/batch 67.58 | loss  3.92 | ppl    50.17\n",
      "| epoch 139 | 60/103 batches | lr 0.0000 | ms/batch 66.90 | loss  3.28 | ppl    26.64\n",
      "| epoch 139 | 90/103 batches | lr 0.0000 | ms/batch 66.44 | loss  2.92 | ppl    18.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 139 | time:  7.99s | valid loss  5.06 | valid ppl   157.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 141, learning rate 0.000053 \n",
      "| epoch 140 | 30/103 batches | lr 0.0000 | ms/batch 66.01 | loss  3.98 | ppl    53.70\n",
      "| epoch 140 | 60/103 batches | lr 0.0000 | ms/batch 65.55 | loss  3.30 | ppl    27.11\n",
      "| epoch 140 | 90/103 batches | lr 0.0000 | ms/batch 67.04 | loss  2.94 | ppl    18.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 140 | time:  8.00s | valid loss  5.07 | valid ppl   158.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 142, learning rate 0.000054 \n",
      "| epoch 141 | 30/103 batches | lr 0.0000 | ms/batch 67.65 | loss  3.92 | ppl    50.24\n",
      "| epoch 141 | 60/103 batches | lr 0.0000 | ms/batch 67.99 | loss  3.37 | ppl    29.02\n",
      "| epoch 141 | 90/103 batches | lr 0.0000 | ms/batch 68.40 | loss  2.99 | ppl    19.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 141 | time:  7.95s | valid loss  5.07 | valid ppl   158.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 143, learning rate 0.000052 \n",
      "| epoch 142 | 30/103 batches | lr 0.0000 | ms/batch 68.60 | loss  3.91 | ppl    50.07\n",
      "| epoch 142 | 60/103 batches | lr 0.0000 | ms/batch 68.12 | loss  3.29 | ppl    26.91\n",
      "| epoch 142 | 90/103 batches | lr 0.0000 | ms/batch 67.13 | loss  3.02 | ppl    20.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 142 | time:  7.97s | valid loss  5.07 | valid ppl   158.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 144, learning rate 0.000052 \n",
      "| epoch 143 | 30/103 batches | lr 0.0000 | ms/batch 69.81 | loss  3.91 | ppl    49.72\n",
      "| epoch 143 | 60/103 batches | lr 0.0000 | ms/batch 66.87 | loss  3.23 | ppl    25.25\n",
      "| epoch 143 | 90/103 batches | lr 0.0000 | ms/batch 68.25 | loss  3.01 | ppl    20.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 143 | time:  7.99s | valid loss  5.07 | valid ppl   159.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 145, learning rate 0.000052 \n",
      "| epoch 144 | 30/103 batches | lr 0.0000 | ms/batch 68.49 | loss  3.90 | ppl    49.47\n",
      "| epoch 144 | 60/103 batches | lr 0.0000 | ms/batch 66.74 | loss  3.26 | ppl    26.10\n",
      "| epoch 144 | 90/103 batches | lr 0.0000 | ms/batch 66.81 | loss  2.92 | ppl    18.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 144 | time:  8.02s | valid loss  5.07 | valid ppl   159.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 146, learning rate 0.000053 \n",
      "| epoch 145 | 30/103 batches | lr 0.0000 | ms/batch 65.87 | loss  4.00 | ppl    54.56\n",
      "| epoch 145 | 60/103 batches | lr 0.0000 | ms/batch 68.29 | loss  3.23 | ppl    25.39\n",
      "| epoch 145 | 90/103 batches | lr 0.0000 | ms/batch 67.48 | loss  2.88 | ppl    17.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 145 | time:  8.07s | valid loss  5.08 | valid ppl   160.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 147, learning rate 0.000054 \n",
      "| epoch 146 | 30/103 batches | lr 0.0000 | ms/batch 67.81 | loss  3.88 | ppl    48.24\n",
      "| epoch 146 | 60/103 batches | lr 0.0000 | ms/batch 68.01 | loss  3.26 | ppl    26.00\n",
      "| epoch 146 | 90/103 batches | lr 0.0000 | ms/batch 68.64 | loss  2.99 | ppl    19.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 146 | time:  8.04s | valid loss  5.09 | valid ppl   162.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 148, learning rate 0.000053 \n",
      "| epoch 147 | 30/103 batches | lr 0.0000 | ms/batch 68.07 | loss  3.87 | ppl    48.16\n",
      "| epoch 147 | 60/103 batches | lr 0.0000 | ms/batch 65.04 | loss  3.25 | ppl    25.70\n",
      "| epoch 147 | 90/103 batches | lr 0.0000 | ms/batch 68.62 | loss  2.88 | ppl    17.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 147 | time:  8.04s | valid loss  5.09 | valid ppl   161.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 149, learning rate 0.000054 \n",
      "| epoch 148 | 30/103 batches | lr 0.0000 | ms/batch 66.19 | loss  3.96 | ppl    52.35\n",
      "| epoch 148 | 60/103 batches | lr 0.0000 | ms/batch 68.69 | loss  3.24 | ppl    25.57\n",
      "| epoch 148 | 90/103 batches | lr 0.0000 | ms/batch 67.17 | loss  2.88 | ppl    17.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 148 | time:  8.07s | valid loss  5.09 | valid ppl   161.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 150, learning rate 0.000053 \n",
      "| epoch 149 | 30/103 batches | lr 0.0000 | ms/batch 66.10 | loss  4.00 | ppl    54.39\n",
      "| epoch 149 | 60/103 batches | lr 0.0000 | ms/batch 67.14 | loss  3.38 | ppl    29.29\n",
      "| epoch 149 | 90/103 batches | lr 0.0000 | ms/batch 63.44 | loss  2.89 | ppl    17.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 149 | time:  8.14s | valid loss  5.09 | valid ppl   162.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 151, learning rate 0.000056 \n",
      "| epoch 150 | 30/103 batches | lr 0.0000 | ms/batch 69.16 | loss  3.88 | ppl    48.57\n",
      "| epoch 150 | 60/103 batches | lr 0.0000 | ms/batch 68.44 | loss  3.25 | ppl    25.89\n",
      "| epoch 150 | 90/103 batches | lr 0.0000 | ms/batch 67.68 | loss  2.95 | ppl    19.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 150 | time:  8.01s | valid loss  5.09 | valid ppl   161.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 152, learning rate 0.000052 \n",
      "| epoch 151 | 30/103 batches | lr 0.0000 | ms/batch 68.08 | loss  3.87 | ppl    47.89\n",
      "| epoch 151 | 60/103 batches | lr 0.0000 | ms/batch 68.38 | loss  3.18 | ppl    24.12\n",
      "| epoch 151 | 90/103 batches | lr 0.0000 | ms/batch 70.06 | loss  2.93 | ppl    18.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 151 | time:  7.98s | valid loss  5.09 | valid ppl   162.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 153, learning rate 0.000052 \n",
      "| epoch 152 | 30/103 batches | lr 0.0000 | ms/batch 69.02 | loss  3.88 | ppl    48.51\n",
      "| epoch 152 | 60/103 batches | lr 0.0000 | ms/batch 69.42 | loss  3.26 | ppl    26.13\n",
      "| epoch 152 | 90/103 batches | lr 0.0000 | ms/batch 67.52 | loss  2.91 | ppl    18.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 152 | time:  7.96s | valid loss  5.09 | valid ppl   162.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 154, learning rate 0.000052 \n",
      "| epoch 153 | 30/103 batches | lr 0.0000 | ms/batch 67.55 | loss  3.86 | ppl    47.62\n",
      "| epoch 153 | 60/103 batches | lr 0.0000 | ms/batch 66.53 | loss  3.19 | ppl    24.27\n",
      "| epoch 153 | 90/103 batches | lr 0.0000 | ms/batch 68.82 | loss  2.91 | ppl    18.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 153 | time:  7.99s | valid loss  5.09 | valid ppl   162.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 155, learning rate 0.000053 \n",
      "| epoch 154 | 30/103 batches | lr 0.0000 | ms/batch 68.60 | loss  3.87 | ppl    47.91\n",
      "| epoch 154 | 60/103 batches | lr 0.0000 | ms/batch 68.05 | loss  3.17 | ppl    23.82\n",
      "| epoch 154 | 90/103 batches | lr 0.0000 | ms/batch 66.04 | loss  2.87 | ppl    17.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 154 | time:  8.02s | valid loss  5.11 | valid ppl   164.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 156, learning rate 0.000053 \n",
      "| epoch 155 | 30/103 batches | lr 0.0000 | ms/batch 67.79 | loss  3.87 | ppl    47.84\n",
      "| epoch 155 | 60/103 batches | lr 0.0000 | ms/batch 68.07 | loss  3.18 | ppl    24.15\n",
      "| epoch 155 | 90/103 batches | lr 0.0000 | ms/batch 68.58 | loss  2.95 | ppl    19.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 155 | time:  8.01s | valid loss  5.10 | valid ppl   164.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 157, learning rate 0.000052 \n",
      "| epoch 156 | 30/103 batches | lr 0.0000 | ms/batch 67.29 | loss  3.88 | ppl    48.36\n",
      "| epoch 156 | 60/103 batches | lr 0.0000 | ms/batch 70.16 | loss  3.22 | ppl    24.93\n",
      "| epoch 156 | 90/103 batches | lr 0.0000 | ms/batch 67.42 | loss  2.90 | ppl    18.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 156 | time:  7.99s | valid loss  5.10 | valid ppl   163.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 158, learning rate 0.000052 \n",
      "| epoch 157 | 30/103 batches | lr 0.0000 | ms/batch 69.00 | loss  3.86 | ppl    47.66\n",
      "| epoch 157 | 60/103 batches | lr 0.0000 | ms/batch 68.37 | loss  3.19 | ppl    24.41\n",
      "| epoch 157 | 90/103 batches | lr 0.0000 | ms/batch 67.17 | loss  2.91 | ppl    18.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 157 | time:  8.06s | valid loss  5.10 | valid ppl   163.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 159, learning rate 0.000053 \n",
      "| epoch 158 | 30/103 batches | lr 0.0000 | ms/batch 69.52 | loss  3.85 | ppl    47.19\n",
      "| epoch 158 | 60/103 batches | lr 0.0000 | ms/batch 66.50 | loss  3.18 | ppl    24.06\n",
      "| epoch 158 | 90/103 batches | lr 0.0000 | ms/batch 69.47 | loss  2.89 | ppl    17.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 158 | time:  8.01s | valid loss  5.11 | valid ppl   165.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 160, learning rate 0.000052 \n",
      "| epoch 159 | 30/103 batches | lr 0.0000 | ms/batch 68.57 | loss  3.91 | ppl    49.94\n",
      "| epoch 159 | 60/103 batches | lr 0.0000 | ms/batch 65.28 | loss  3.20 | ppl    24.58\n",
      "| epoch 159 | 90/103 batches | lr 0.0000 | ms/batch 67.22 | loss  2.85 | ppl    17.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 159 | time:  8.06s | valid loss  5.11 | valid ppl   165.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 161, learning rate 0.000053 \n",
      "| epoch 160 | 30/103 batches | lr 0.0000 | ms/batch 68.45 | loss  3.84 | ppl    46.54\n",
      "| epoch 160 | 60/103 batches | lr 0.0000 | ms/batch 65.83 | loss  3.14 | ppl    23.19\n",
      "| epoch 160 | 90/103 batches | lr 0.0000 | ms/batch 65.92 | loss  2.81 | ppl    16.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 160 | time:  8.06s | valid loss  5.11 | valid ppl   165.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 162, learning rate 0.000054 \n",
      "| epoch 161 | 30/103 batches | lr 0.0000 | ms/batch 66.80 | loss  3.92 | ppl    50.30\n",
      "| epoch 161 | 60/103 batches | lr 0.0000 | ms/batch 67.28 | loss  3.18 | ppl    24.09\n",
      "| epoch 161 | 90/103 batches | lr 0.0000 | ms/batch 67.60 | loss  2.83 | ppl    17.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 161 | time:  8.11s | valid loss  5.12 | valid ppl   167.81\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 163, learning rate 0.000054 \n",
      "| epoch 162 | 30/103 batches | lr 0.0000 | ms/batch 68.06 | loss  3.86 | ppl    47.37\n",
      "| epoch 162 | 60/103 batches | lr 0.0000 | ms/batch 68.73 | loss  3.23 | ppl    25.36\n",
      "| epoch 162 | 90/103 batches | lr 0.0000 | ms/batch 67.44 | loss  2.89 | ppl    18.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 162 | time:  8.09s | valid loss  5.12 | valid ppl   166.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 164, learning rate 0.000053 \n",
      "| epoch 163 | 30/103 batches | lr 0.0000 | ms/batch 68.69 | loss  3.94 | ppl    51.18\n",
      "| epoch 163 | 60/103 batches | lr 0.0000 | ms/batch 69.61 | loss  3.17 | ppl    23.80\n",
      "| epoch 163 | 90/103 batches | lr 0.0000 | ms/batch 66.19 | loss  2.86 | ppl    17.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 163 | time:  8.15s | valid loss  5.11 | valid ppl   166.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 165, learning rate 0.000054 \n",
      "| epoch 164 | 30/103 batches | lr 0.0000 | ms/batch 68.79 | loss  3.84 | ppl    46.75\n",
      "| epoch 164 | 60/103 batches | lr 0.0000 | ms/batch 67.19 | loss  3.13 | ppl    22.80\n",
      "| epoch 164 | 90/103 batches | lr 0.0000 | ms/batch 69.55 | loss  2.85 | ppl    17.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 164 | time:  8.01s | valid loss  5.12 | valid ppl   166.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 166, learning rate 0.000052 \n",
      "| epoch 165 | 30/103 batches | lr 0.0000 | ms/batch 68.80 | loss  3.83 | ppl    46.08\n",
      "| epoch 165 | 60/103 batches | lr 0.0000 | ms/batch 69.34 | loss  3.19 | ppl    24.22\n",
      "| epoch 165 | 90/103 batches | lr 0.0000 | ms/batch 68.10 | loss  2.87 | ppl    17.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 165 | time:  7.99s | valid loss  5.12 | valid ppl   167.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 167, learning rate 0.000052 \n",
      "| epoch 166 | 30/103 batches | lr 0.0000 | ms/batch 66.21 | loss  3.88 | ppl    48.53\n",
      "| epoch 166 | 60/103 batches | lr 0.0000 | ms/batch 67.86 | loss  3.10 | ppl    22.25\n",
      "| epoch 166 | 90/103 batches | lr 0.0000 | ms/batch 67.33 | loss  2.74 | ppl    15.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 166 | time:  8.06s | valid loss  5.12 | valid ppl   167.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 168, learning rate 0.000054 \n",
      "| epoch 167 | 30/103 batches | lr 0.0000 | ms/batch 71.54 | loss  3.81 | ppl    44.95\n",
      "| epoch 167 | 60/103 batches | lr 0.0000 | ms/batch 71.49 | loss  3.15 | ppl    23.39\n",
      "| epoch 167 | 90/103 batches | lr 0.0000 | ms/batch 67.31 | loss  2.87 | ppl    17.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 167 | time:  8.18s | valid loss  5.13 | valid ppl   168.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 169, learning rate 0.000052 \n",
      "| epoch 168 | 30/103 batches | lr 0.0000 | ms/batch 71.05 | loss  3.84 | ppl    46.41\n",
      "| epoch 168 | 60/103 batches | lr 0.0000 | ms/batch 67.34 | loss  3.18 | ppl    24.14\n",
      "| epoch 168 | 90/103 batches | lr 0.0000 | ms/batch 69.24 | loss  2.77 | ppl    15.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 168 | time:  8.20s | valid loss  5.13 | valid ppl   168.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 170, learning rate 0.000054 \n",
      "| epoch 169 | 30/103 batches | lr 0.0000 | ms/batch 68.03 | loss  3.80 | ppl    44.61\n",
      "| epoch 169 | 60/103 batches | lr 0.0000 | ms/batch 66.20 | loss  3.09 | ppl    22.02\n",
      "| epoch 169 | 90/103 batches | lr 0.0000 | ms/batch 67.33 | loss  2.75 | ppl    15.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 169 | time:  8.06s | valid loss  5.14 | valid ppl   170.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 171, learning rate 0.000054 \n",
      "| epoch 170 | 30/103 batches | lr 0.0000 | ms/batch 66.28 | loss  3.87 | ppl    48.16\n",
      "| epoch 170 | 60/103 batches | lr 0.0000 | ms/batch 69.91 | loss  3.11 | ppl    22.33\n",
      "| epoch 170 | 90/103 batches | lr 0.0000 | ms/batch 68.77 | loss  2.86 | ppl    17.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 170 | time:  8.04s | valid loss  5.14 | valid ppl   170.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 172, learning rate 0.000053 \n",
      "| epoch 171 | 30/103 batches | lr 0.0000 | ms/batch 67.25 | loss  3.84 | ppl    46.56\n",
      "| epoch 171 | 60/103 batches | lr 0.0000 | ms/batch 68.08 | loss  3.10 | ppl    22.17\n",
      "| epoch 171 | 90/103 batches | lr 0.0000 | ms/batch 66.67 | loss  2.74 | ppl    15.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 171 | time:  8.02s | valid loss  5.14 | valid ppl   170.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 173, learning rate 0.000053 \n",
      "| epoch 172 | 30/103 batches | lr 0.0000 | ms/batch 66.02 | loss  3.91 | ppl    49.71\n",
      "| epoch 172 | 60/103 batches | lr 0.0000 | ms/batch 66.60 | loss  3.14 | ppl    23.07\n",
      "| epoch 172 | 90/103 batches | lr 0.0000 | ms/batch 68.29 | loss  2.75 | ppl    15.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 172 | time:  8.04s | valid loss  5.14 | valid ppl   170.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 174, learning rate 0.000053 \n",
      "| epoch 173 | 30/103 batches | lr 0.0000 | ms/batch 67.68 | loss  3.79 | ppl    44.36\n",
      "| epoch 173 | 60/103 batches | lr 0.0000 | ms/batch 67.97 | loss  3.09 | ppl    21.93\n",
      "| epoch 173 | 90/103 batches | lr 0.0000 | ms/batch 68.14 | loss  2.81 | ppl    16.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 173 | time:  8.02s | valid loss  5.14 | valid ppl   171.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 175, learning rate 0.000053 \n",
      "| epoch 174 | 30/103 batches | lr 0.0000 | ms/batch 68.60 | loss  3.89 | ppl    48.94\n",
      "| epoch 174 | 60/103 batches | lr 0.0000 | ms/batch 68.45 | loss  3.11 | ppl    22.40\n",
      "| epoch 174 | 90/103 batches | lr 0.0000 | ms/batch 65.54 | loss  2.81 | ppl    16.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 174 | time:  8.27s | valid loss  5.14 | valid ppl   171.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 176, learning rate 0.000055 \n",
      "| epoch 175 | 30/103 batches | lr 0.0000 | ms/batch 69.52 | loss  3.78 | ppl    43.92\n",
      "| epoch 175 | 60/103 batches | lr 0.0000 | ms/batch 67.76 | loss  3.08 | ppl    21.86\n",
      "| epoch 175 | 90/103 batches | lr 0.0000 | ms/batch 68.69 | loss  2.78 | ppl    16.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 175 | time:  7.98s | valid loss  5.15 | valid ppl   172.44\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 177, learning rate 0.000052 \n",
      "| epoch 176 | 30/103 batches | lr 0.0000 | ms/batch 64.99 | loss  3.87 | ppl    47.95\n",
      "| epoch 176 | 60/103 batches | lr 0.0000 | ms/batch 67.01 | loss  3.10 | ppl    22.17\n",
      "| epoch 176 | 90/103 batches | lr 0.0000 | ms/batch 67.53 | loss  2.72 | ppl    15.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 176 | time:  8.03s | valid loss  5.15 | valid ppl   172.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 178, learning rate 0.000054 \n",
      "| epoch 177 | 30/103 batches | lr 0.0000 | ms/batch 66.98 | loss  3.80 | ppl    44.71\n",
      "| epoch 177 | 60/103 batches | lr 0.0000 | ms/batch 68.06 | loss  3.05 | ppl    21.21\n",
      "| epoch 177 | 90/103 batches | lr 0.0000 | ms/batch 67.07 | loss  2.70 | ppl    14.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 177 | time:  8.02s | valid loss  5.15 | valid ppl   172.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 179, learning rate 0.000053 \n",
      "| epoch 178 | 30/103 batches | lr 0.0000 | ms/batch 66.60 | loss  3.82 | ppl    45.45\n",
      "| epoch 178 | 60/103 batches | lr 0.0000 | ms/batch 67.40 | loss  3.05 | ppl    21.04\n",
      "| epoch 178 | 90/103 batches | lr 0.0000 | ms/batch 68.04 | loss  2.70 | ppl    14.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 178 | time:  8.02s | valid loss  5.16 | valid ppl   173.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 180, learning rate 0.000053 \n",
      "| epoch 179 | 30/103 batches | lr 0.0000 | ms/batch 65.65 | loss  3.88 | ppl    48.40\n",
      "| epoch 179 | 60/103 batches | lr 0.0000 | ms/batch 65.78 | loss  3.06 | ppl    21.35\n",
      "| epoch 179 | 90/103 batches | lr 0.0000 | ms/batch 69.47 | loss  2.70 | ppl    14.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 179 | time:  8.01s | valid loss  5.16 | valid ppl   173.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 181, learning rate 0.000054 \n",
      "| epoch 180 | 30/103 batches | lr 0.0000 | ms/batch 68.40 | loss  3.78 | ppl    43.94\n",
      "| epoch 180 | 60/103 batches | lr 0.0000 | ms/batch 70.10 | loss  3.13 | ppl    22.88\n",
      "| epoch 180 | 90/103 batches | lr 0.0000 | ms/batch 65.56 | loss  2.89 | ppl    18.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 180 | time:  8.01s | valid loss  5.16 | valid ppl   173.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 182, learning rate 0.000053 \n",
      "| epoch 181 | 30/103 batches | lr 0.0000 | ms/batch 68.61 | loss  3.77 | ppl    43.43\n",
      "| epoch 181 | 60/103 batches | lr 0.0000 | ms/batch 68.45 | loss  3.04 | ppl    20.99\n",
      "| epoch 181 | 90/103 batches | lr 0.0000 | ms/batch 66.51 | loss  2.76 | ppl    15.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 181 | time:  7.99s | valid loss  5.17 | valid ppl   175.22\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 183, learning rate 0.000052 \n",
      "| epoch 182 | 30/103 batches | lr 0.0000 | ms/batch 67.44 | loss  3.81 | ppl    45.09\n",
      "| epoch 182 | 60/103 batches | lr 0.0000 | ms/batch 65.11 | loss  3.09 | ppl    21.98\n",
      "| epoch 182 | 90/103 batches | lr 0.0000 | ms/batch 67.72 | loss  2.79 | ppl    16.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 182 | time:  8.03s | valid loss  5.17 | valid ppl   175.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 184, learning rate 0.000054 \n",
      "| epoch 183 | 30/103 batches | lr 0.0000 | ms/batch 66.87 | loss  3.79 | ppl    44.17\n",
      "| epoch 183 | 60/103 batches | lr 0.0000 | ms/batch 66.58 | loss  3.07 | ppl    21.43\n",
      "| epoch 183 | 90/103 batches | lr 0.0000 | ms/batch 68.79 | loss  2.67 | ppl    14.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 183 | time:  8.04s | valid loss  5.18 | valid ppl   177.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 185, learning rate 0.000053 \n",
      "| epoch 184 | 30/103 batches | lr 0.0000 | ms/batch 66.14 | loss  3.84 | ppl    46.54\n",
      "| epoch 184 | 60/103 batches | lr 0.0000 | ms/batch 65.27 | loss  3.04 | ppl    21.01\n",
      "| epoch 184 | 90/103 batches | lr 0.0000 | ms/batch 66.32 | loss  2.68 | ppl    14.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 184 | time:  8.04s | valid loss  5.17 | valid ppl   176.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 186, learning rate 0.000054 \n",
      "| epoch 185 | 30/103 batches | lr 0.0000 | ms/batch 67.47 | loss  3.77 | ppl    43.36\n",
      "| epoch 185 | 60/103 batches | lr 0.0000 | ms/batch 65.81 | loss  3.12 | ppl    22.70\n",
      "| epoch 185 | 90/103 batches | lr 0.0000 | ms/batch 66.98 | loss  2.69 | ppl    14.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 185 | time:  8.05s | valid loss  5.18 | valid ppl   177.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 187, learning rate 0.000054 \n",
      "| epoch 186 | 30/103 batches | lr 0.0000 | ms/batch 68.22 | loss  3.75 | ppl    42.62\n",
      "| epoch 186 | 60/103 batches | lr 0.0000 | ms/batch 66.29 | loss  3.04 | ppl    20.90\n",
      "| epoch 186 | 90/103 batches | lr 0.0000 | ms/batch 66.95 | loss  2.64 | ppl    13.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 186 | time:  8.04s | valid loss  5.19 | valid ppl   178.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 188, learning rate 0.000054 \n",
      "| epoch 187 | 30/103 batches | lr 0.0000 | ms/batch 69.89 | loss  3.73 | ppl    41.78\n",
      "| epoch 187 | 60/103 batches | lr 0.0000 | ms/batch 67.06 | loss  3.00 | ppl    19.99\n",
      "| epoch 187 | 90/103 batches | lr 0.0000 | ms/batch 67.43 | loss  2.71 | ppl    15.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 187 | time:  8.03s | valid loss  5.18 | valid ppl   178.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 189, learning rate 0.000053 \n",
      "| epoch 188 | 30/103 batches | lr 0.0000 | ms/batch 67.29 | loss  3.78 | ppl    43.65\n",
      "| epoch 188 | 60/103 batches | lr 0.0000 | ms/batch 68.49 | loss  3.01 | ppl    20.21\n",
      "| epoch 188 | 90/103 batches | lr 0.0000 | ms/batch 68.43 | loss  2.70 | ppl    14.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 188 | time:  8.04s | valid loss  5.19 | valid ppl   178.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 190, learning rate 0.000053 \n",
      "| epoch 189 | 30/103 batches | lr 0.0000 | ms/batch 67.90 | loss  3.76 | ppl    42.83\n",
      "| epoch 189 | 60/103 batches | lr 0.0000 | ms/batch 66.91 | loss  3.01 | ppl    20.24\n",
      "| epoch 189 | 90/103 batches | lr 0.0000 | ms/batch 67.91 | loss  2.63 | ppl    13.89\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 189 | time:  8.01s | valid loss  5.19 | valid ppl   179.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 191, learning rate 0.000053 \n",
      "| epoch 190 | 30/103 batches | lr 0.0000 | ms/batch 66.79 | loss  3.79 | ppl    44.36\n",
      "| epoch 190 | 60/103 batches | lr 0.0000 | ms/batch 67.60 | loss  3.01 | ppl    20.25\n",
      "| epoch 190 | 90/103 batches | lr 0.0000 | ms/batch 65.57 | loss  2.64 | ppl    13.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 190 | time:  8.06s | valid loss  5.19 | valid ppl   180.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 192, learning rate 0.000054 \n",
      "| epoch 191 | 30/103 batches | lr 0.0000 | ms/batch 69.29 | loss  3.74 | ppl    41.91\n",
      "| epoch 191 | 60/103 batches | lr 0.0000 | ms/batch 66.25 | loss  3.02 | ppl    20.50\n",
      "| epoch 191 | 90/103 batches | lr 0.0000 | ms/batch 67.39 | loss  2.61 | ppl    13.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 191 | time:  8.06s | valid loss  5.20 | valid ppl   180.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 193, learning rate 0.000053 \n",
      "| epoch 192 | 30/103 batches | lr 0.0000 | ms/batch 67.76 | loss  3.76 | ppl    42.85\n",
      "| epoch 192 | 60/103 batches | lr 0.0000 | ms/batch 66.74 | loss  2.97 | ppl    19.56\n",
      "| epoch 192 | 90/103 batches | lr 0.0000 | ms/batch 66.56 | loss  2.62 | ppl    13.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 192 | time:  8.02s | valid loss  5.20 | valid ppl   180.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 194, learning rate 0.000053 \n",
      "| epoch 193 | 30/103 batches | lr 0.0000 | ms/batch 67.88 | loss  3.74 | ppl    42.04\n",
      "| epoch 193 | 60/103 batches | lr 0.0000 | ms/batch 66.36 | loss  2.98 | ppl    19.73\n",
      "| epoch 193 | 90/103 batches | lr 0.0000 | ms/batch 68.23 | loss  2.58 | ppl    13.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 193 | time:  8.06s | valid loss  5.20 | valid ppl   181.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 195, learning rate 0.000053 \n",
      "| epoch 194 | 30/103 batches | lr 0.0000 | ms/batch 69.11 | loss  3.72 | ppl    41.36\n",
      "| epoch 194 | 60/103 batches | lr 0.0000 | ms/batch 68.92 | loss  2.96 | ppl    19.21\n",
      "| epoch 194 | 90/103 batches | lr 0.0000 | ms/batch 68.64 | loss  2.65 | ppl    14.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 194 | time:  8.05s | valid loss  5.21 | valid ppl   182.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 196, learning rate 0.000052 \n",
      "| epoch 195 | 30/103 batches | lr 0.0000 | ms/batch 68.32 | loss  3.73 | ppl    41.47\n",
      "| epoch 195 | 60/103 batches | lr 0.0000 | ms/batch 65.77 | loss  2.98 | ppl    19.63\n",
      "| epoch 195 | 90/103 batches | lr 0.0000 | ms/batch 68.22 | loss  2.58 | ppl    13.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 195 | time:  8.06s | valid loss  5.21 | valid ppl   182.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 197, learning rate 0.000054 \n",
      "| epoch 196 | 30/103 batches | lr 0.0000 | ms/batch 66.71 | loss  3.84 | ppl    46.46\n",
      "| epoch 196 | 60/103 batches | lr 0.0000 | ms/batch 68.00 | loss  2.99 | ppl    19.95\n",
      "| epoch 196 | 90/103 batches | lr 0.0000 | ms/batch 68.62 | loss  2.65 | ppl    14.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 196 | time:  7.99s | valid loss  5.21 | valid ppl   183.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "Start epoch 198, learning rate 0.000053 \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        total_loss = 0\n",
    "        print('Start epoch %d, learning rate %f '%(epoch + 1, opt.state_dict()['param_groups'][0]['lr']))\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        batch, i = 0, 0\n",
    "        while i < train_data.size(0) - 2:\n",
    "            bptt = bptt0 if np.random.random() < 0.95 else bptt0 / 2.\n",
    "            # Prevent excessively small or negative sequence lengths\n",
    "            seq_len = max(5, int(np.random.normal(bptt, 5))) # loc 70, scale 5\n",
    "            # There's a very small chance that it could select a very long sequence length resulting in OOM\n",
    "            seq_len = min(seq_len, bptt + max_seq_len_delta)\n",
    "\n",
    "            data, targets = get_batch(train_data, i, seq_len=seq_len)\n",
    "            seq_len = data.shape[1]\n",
    "            lengths = torch.ones(data.shape[0], device=device, dtype=torch.long) * seq_len\n",
    "\n",
    "            opt.zero_grad()\n",
    "            output, self_attn = model.forward(data, lengths)\n",
    "            loss = criterion(output, targets.view(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            batch += 1\n",
    "            i += seq_len\n",
    "            \n",
    "            new_lr = np.power(emb_dim, -0.5) * np.min([\n",
    "                np.power((batch), -0.5),\n",
    "                np.power(warmup_steps, -1.5) * (batch)])\n",
    "            for param_group in opt.param_groups:\n",
    "                param_group['lr'] = new_lr\n",
    "\n",
    "            if batch % log_interval == 0 and batch > 0:\n",
    "                cur_loss = loss.item()\n",
    "                elapsed = time.time() - start_time\n",
    "                logging('| epoch {:3d} | {}/{} batches | lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                        'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // bptt0, opt.param_groups[0]['lr'],\n",
    "                    elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
    "                total_loss = 0\n",
    "                start_time = time.time()\n",
    "\n",
    "        val_loss = evaluate(val_data, model, voc_size, bptt0)\n",
    "        logging('-' * 89)\n",
    "        logging('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                           val_loss, math.exp(val_loss)))\n",
    "        logging('-' * 89)\n",
    "\n",
    "        best_val_loss.append(val_loss)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logging('-' * 89)\n",
    "    logging('Exiting from training early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
