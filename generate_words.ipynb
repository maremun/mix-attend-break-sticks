{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import mos.mos_data as data\n",
    "import sys\n",
    "sys.path.append(\"./mos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = \"./data/penn/\"\n",
    "model_filename = \"./mos/PTB-20180531-133208/model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (lockdrop): LockedDropout()\n",
       "  (encoder): Embedding(10000, 280)\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDrop(\n",
       "      (module): LSTM(280, 960)\n",
       "    )\n",
       "    (1): WeightDrop(\n",
       "      (module): LSTM(960, 960)\n",
       "    )\n",
       "    (2): WeightDrop(\n",
       "      (module): LSTM(960, 620)\n",
       "    )\n",
       "  )\n",
       "  (head): MoShead(\n",
       "    (lockdrop): LockedDropout()\n",
       "    (prior): Linear(in_features=620, out_features=15, bias=False)\n",
       "    (latent): Sequential(\n",
       "      (0): Linear(in_features=620, out_features=4200, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (decoder): Linear(in_features=280, out_features=10000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(model_filename)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = data.Corpus(data_file)\n",
    "ntokens = len(corpus.dictionary)\n",
    "hidden = model.init_hidden(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.rand(1, 1, requires_grad=False).mul(ntokens).long()\n",
    "if torch.cuda.is_available():\n",
    "    input.data = input.data.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katrutsa/anaconda2/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py:491: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refineries meat stabilized enable credentials require farmers pencils remedy executing refuse minimum principals aftershocks credentials admits penalty guest air-freight coordinate\n",
      "ideological hepatitis welcomed although dizzying jobs clear n.y. limiting hybrid robertson exclusivity opec bloated hydro-quebec afterward overnight parade aftermath spurred\n",
      "riders manufacturer fired enterprises trail roller-coaster applied sinking responsible earned san fargo concentrate shots daly unfair efficient mink seven strongest\n",
      "exception justice sooner issued withdrawal compounded lifted marine diplomatic promise hud dropping politicians inclined let freeway become injection fees luis\n",
      "thieves province move laurence underwritten eased attendance survive strong highways york-based demanding dump jr remained plaintiffs palmer convinced wondering warrant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# input = Variable(torch.rand(1, 1).mul(ntokens).long(), volatile=True)\n",
    "num_words = 100\n",
    "temperature = 1.\n",
    "output_string = \"\"\n",
    "for i in range(num_words):\n",
    "    output, hidden = model(input, hidden, return_prob=True)\n",
    "    word_weights = output.squeeze().data.div(temperature).exp()\n",
    "    word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "    input.data.fill_(word_idx)\n",
    "    word = corpus.dictionary.idx2word[word_idx]\n",
    "#     outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n",
    "    output_string = output_string + word\n",
    "    if i % 20 == 19:\n",
    "        output_string = output_string + \"\\n\"\n",
    "    else:\n",
    "        output_string = output_string + \" \"\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pytorch]",
   "language": "python",
   "name": "Python [pytorch]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
