{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revised and fixed code from https://github.com/JayParks/transformer (MT) for LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stripped the code from the JayParks repo for MT Transformer. Introduced a few updates and changes for speed, but it's still frustratingly slow. Possible improvement - speed it up.\n",
    "\n",
    "Another issue - hyperparameter search for language modelling (number of heads, number of self-attention layers, etc). Does not work well from the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Speed up\n",
    "* Tune hyperparams (now it's diverging)\n",
    "* Add MoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "torch.cuda.device(2)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as pad\n",
    "from torch.nn.utils import clip_grad_norm_ as clip\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import const\n",
    "from data import *\n",
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "Loading data from data/penn/train.txt ...\n",
      "=========================================================================================\n",
      "Loading data from data/penn/valid.txt ...\n",
      "=========================================================================================\n",
      "Loading data from data/penn/test.txt ...\n"
     ]
    }
   ],
   "source": [
    "ptb_datapath_train = 'data/penn/train.txt'\n",
    "ptb_datapath_valid = 'data/penn/valid.txt'\n",
    "ptb_datapath_test = 'data/penn/test.txt'\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "ptb_train = DataSet(ptb_datapath_train, batch_size, display_freq=0, max_len=90, trunc_len=90)\n",
    "ptb_valid = DataSet(ptb_datapath_valid, batch_size, display_freq=0, max_len=90, trunc_len=90)\n",
    "ptb_test = DataSet(ptb_datapath_test, batch_size, display_freq=0, max_len=90, trunc_len=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionary...\n",
      "Done.\n",
      "Save dictionary at data/penn/train.txt.dict\n",
      "Index tokens ...\n",
      "42068 sentences were processed, 0 longer than maximum length,0 were ignored because zero length\n",
      "=========================================================================================\n",
      "Data discription:\n",
      "Data name : data/penn/train.txt\n",
      "Number of sentence : 42068\n",
      "Number of tokens : 887521\n",
      "Vocabulary size : 10000\n",
      "Number of batches : 328\n",
      "Batch size : 128\n",
      "Done.\n",
      "Index tokens ...\n",
      "3370 sentences were processed, 0 longer than maximum length,0 were ignored because zero length\n",
      "=========================================================================================\n",
      "Data discription:\n",
      "Data name : data/penn/valid.txt\n",
      "Number of sentence : 3370\n",
      "Number of tokens : 70390\n",
      "Vocabulary size : 10000\n",
      "Number of batches : 26\n",
      "Batch size : 128\n",
      "Done.\n",
      "Index tokens ...\n",
      "3761 sentences were processed, 0 longer than maximum length,0 were ignored because zero length\n",
      "=========================================================================================\n",
      "Data discription:\n",
      "Data name : data/penn/test.txt\n",
      "Number of sentence : 3761\n",
      "Number of tokens : 78669\n",
      "Vocabulary size : 10000\n",
      "Number of batches : 29\n",
      "Batch size : 128\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "ptb_train.build_dict()\n",
    "ptb_valid.change_dict(ptb_train.dictionary)\n",
    "ptb_test.change_dict(ptb_train.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = ptb_train.num_vocb\n",
    "emb_dim = 512\n",
    "d_k = 64\n",
    "d_v = 64\n",
    "n_layers = 2\n",
    "n_heads = 4\n",
    "d_ff = 2048\n",
    "max_tgt_seq_len = 90\n",
    "dropout = 0.1\n",
    "weighted_model = False\n",
    "share_proj_weight = True\n",
    "lr = 1e-3\n",
    "n_epochs = 30\n",
    "clip_grad = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharing target embedding and projection..\n"
     ]
    }
   ],
   "source": [
    "model = LMTransformer(n_layers, d_k, d_v, emb_dim, d_ff,\n",
    "                      n_heads, max_tgt_seq_len, voc_size,\n",
    "                      dropout, weighted_model, share_proj_weight)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=const.PAD)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "opt = optim.Adam(model.trainable_params(), lr=lr)\n",
    "# lr_lambda = lambda epoch: 0.99 ** epoch\n",
    "lrsched = StepLR(opt, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 1, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.71batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  7.75batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Batch : 327 / 328, Loss : 5.702489, Perplexity : 299.612289, Time : 121.237305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.73batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 5.133783\n",
      "Validation Perplexity : 169.657661\n",
      "Start epoch 2, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:00<00:00,  2.71batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  7.92batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Batch : 327 / 328, Loss : 4.874813, Perplexity : 130.949660, Time : 120.998704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.52batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 4.907077\n",
      "Validation Perplexity : 135.243477\n",
      "Start epoch 3, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.71batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  7.89batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Batch : 327 / 328, Loss : 4.534898, Perplexity : 93.213973, Time : 121.122315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.61batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 4.829746\n",
      "Validation Perplexity : 125.179180\n",
      "Start epoch 4, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.69batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  7.85batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Batch : 327 / 328, Loss : 4.289405, Perplexity : 72.923101, Time : 121.794339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.51batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 4.818284\n",
      "Validation Perplexity : 123.752517\n",
      "Start epoch 5, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.71batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  7.62batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Batch : 327 / 328, Loss : 4.089971, Perplexity : 59.738153, Time : 121.294400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.72batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 4.846339\n",
      "Validation Perplexity : 127.273587\n",
      "Start epoch 6, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.71batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  7.83batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Batch : 327 / 328, Loss : 3.920071, Perplexity : 50.404037, Time : 121.199066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.72batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 4.865344\n",
      "Validation Perplexity : 129.715576\n",
      "Start epoch 7, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.70batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  8.28batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7, Batch : 327 / 328, Loss : 3.767682, Perplexity : 43.279606, Time : 121.382798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.76batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 4.924917\n",
      "Validation Perplexity : 137.677976\n",
      "Start epoch 8, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:00<00:00,  2.72batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  8.21batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8, Batch : 327 / 328, Loss : 3.631104, Perplexity : 37.754487, Time : 120.860556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.73batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 4.981597\n",
      "Validation Perplexity : 145.706839\n",
      "Start epoch 9, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.70batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  8.16batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Batch : 327 / 328, Loss : 3.504425, Perplexity : 33.262320, Time : 121.500200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.79batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 5.043568\n",
      "Validation Perplexity : 155.022185\n",
      "Start epoch 10, learning rate 0.001000 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.70batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  8.19batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Batch : 327 / 328, Loss : 3.388829, Perplexity : 29.631234, Time : 121.482503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.84batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 5.107677\n",
      "Validation Perplexity : 165.286014\n",
      "Start epoch 11, learning rate 0.000500 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.71batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  7.90batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11, Batch : 327 / 328, Loss : 3.041171, Perplexity : 20.929747, Time : 121.131451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.67batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 5.212470\n",
      "Validation Perplexity : 183.546788\n",
      "Start epoch 12, learning rate 0.000500 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:00<00:00,  2.73batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  8.37batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12, Batch : 327 / 328, Loss : 2.912203, Perplexity : 18.397279, Time : 120.404881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.83batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 5.307598\n",
      "Validation Perplexity : 201.864733\n",
      "Start epoch 13, learning rate 0.000500 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [02:01<00:00,  2.71batches/s]\n",
      "  3%|▎         | 1/29 [00:00<00:03,  8.02batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13, Batch : 327 / 328, Loss : 2.829475, Perplexity : 16.936575, Time : 121.257781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  7.47batches/s]\n",
      "  0%|          | 0/328 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 5.365556\n",
      "Validation Perplexity : 213.910039\n",
      "Start epoch 14, learning rate 0.000500 \n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 170/328 [01:02<00:58,  2.72batches/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    lrsched.step()\n",
    "    acc_loss = 0\n",
    "    print('Start epoch %d, learning rate %f '%(epoch + 1, opt.state_dict()['param_groups'][0]['lr']))\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    ptb_train.shuffle()\n",
    "    for batch_idx in tqdm(range(ptb_train.num_batch), unit='batches'):\n",
    "        data, lengths, target = ptb_train.get_batch(batch_idx)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        output, self_attn = model.forward(data, lengths)\n",
    "        loss = criterion(output, target.view(-1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        acc_loss += loss.item()\n",
    "\n",
    "    avg_loss = acc_loss / ptb_train.num_batch\n",
    "    print('Epoch : %d, Batch : %d / %d, Loss : %f, Perplexity : %f, Time : %f' \n",
    "          % (epoch + 1, batch_idx, ptb_train.num_batch,\n",
    "             avg_loss, math.exp(avg_loss),\n",
    "             time.time() - start_time))\n",
    "\n",
    "    acc_loss = 0\n",
    "    model.eval()\n",
    "    for batch_idx in tqdm(range(ptb_test.num_batch), unit='batches'):\n",
    "        data, lengths, target = ptb_test[batch_idx]\n",
    "        output, self_attn = model.forward(data, lengths)\n",
    "        loss = criterion(output, target.view(-1))\n",
    "        acc_loss += loss.item()\n",
    "\n",
    "    val_loss = acc_loss / ptb_test.num_batch\n",
    "    print('Validation Loss : %f' % val_loss)\n",
    "    print('Validation Perplexity : %f' % math.exp(val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
